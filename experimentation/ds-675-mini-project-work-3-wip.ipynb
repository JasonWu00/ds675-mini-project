{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1733506,"sourceType":"datasetVersion","datasetId":6012}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Team Members: Brian Phung Tran, Mickayla Sujkowski, Ze Hong (Jason) Wu\n\nLink to video report: TO BE INSERTED LATER","metadata":{}},{"cell_type":"markdown","source":"## Objectives\n\nThe \"Rain in Australia\" data set contains around 140,000 entries of daily records of meteorological data at different places in Australia, from 2007 to 2017, collected by the Australian Meteorological Bureau. Additional information can be found in the dataset's Kaggle page, linked here: https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package/data \n\nThe goal of our project is to develop supervised training models that can be used to predict for two different features in the Rain in Australia data set: \"RainToday\", a categorical feature which describes whether there was rain for a given day and location in Australia, and \"Rainfall\", a numerical feature which describes the amount of rainfall in centimeters for the given day and location.","metadata":{}},{"cell_type":"markdown","source":"## Initial Steps: Adding Data\n\nThis is a Kaggle notebook, which allows us to add Kaggle datasets to the notebook using the File->Add Input option on Kaggle's editor. If you (the reader) are trying to replicate this on Google Colab, you might want to download the Rain in Australia dataset to your Google Drive before linking Drive to your notebook. If you are trying to replicate this on your local device, you might want to download and unzip the dataset to your local directory.","metadata":{}},{"cell_type":"code","source":"! ls /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T18:58:43.009037Z","iopub.execute_input":"2025-04-23T18:58:43.009503Z","iopub.status.idle":"2025-04-23T18:58:43.142288Z","shell.execute_reply.started":"2025-04-23T18:58:43.009470Z","shell.execute_reply":"2025-04-23T18:58:43.140529Z"}},"outputs":[{"name":"stdout","text":"weather-dataset-rattle-package\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# This is the default Kaggle opening notebook cell.\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# other imports for model training, testing.\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom scipy import stats # for removing outliers\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.decomposition import PCA\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:25:13.690378Z","iopub.execute_input":"2025-04-30T05:25:13.690567Z","iopub.status.idle":"2025-04-30T05:25:17.584622Z","shell.execute_reply.started":"2025-04-30T05:25:13.690550Z","shell.execute_reply":"2025-04-30T05:25:17.583798Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Exploratory Inspection\n\nWe begin by looking at the data set. Some of our observations will be discussed below.\n\nAdjust the read_csv directory to wherever you placed the .csv file, if necessary.","metadata":{}},{"cell_type":"code","source":"file_location = \"/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv\" # Adjust as needed\ndf = pd.read_csv(file_location)\ndf = df.replace(np.nan, None) # for ease of work later on\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:46:58.802485Z","iopub.execute_input":"2025-04-30T05:46:58.803126Z","iopub.status.idle":"2025-04-30T05:46:59.381203Z","shell.execute_reply.started":"2025-04-30T05:46:58.803098Z","shell.execute_reply":"2025-04-30T05:46:59.380430Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"         Date Location MinTemp MaxTemp Rainfall Evaporation Sunshine  \\\n0  2008-12-01   Albury    13.4    22.9      0.6        None     None   \n1  2008-12-02   Albury     7.4    25.1      0.0        None     None   \n2  2008-12-03   Albury    12.9    25.7      0.0        None     None   \n3  2008-12-04   Albury     9.2    28.0      0.0        None     None   \n4  2008-12-05   Albury    17.5    32.3      1.0        None     None   \n5  2008-12-06   Albury    14.6    29.7      0.2        None     None   \n6  2008-12-07   Albury    14.3    25.0      0.0        None     None   \n7  2008-12-08   Albury     7.7    26.7      0.0        None     None   \n8  2008-12-09   Albury     9.7    31.9      0.0        None     None   \n9  2008-12-10   Albury    13.1    30.1      1.4        None     None   \n\n  WindGustDir WindGustSpeed WindDir9am  ... Humidity9am Humidity3pm  \\\n0           W          44.0          W  ...        71.0        22.0   \n1         WNW          44.0        NNW  ...        44.0        25.0   \n2         WSW          46.0          W  ...        38.0        30.0   \n3          NE          24.0         SE  ...        45.0        16.0   \n4           W          41.0        ENE  ...        82.0        33.0   \n5         WNW          56.0          W  ...        55.0        23.0   \n6           W          50.0         SW  ...        49.0        19.0   \n7           W          35.0        SSE  ...        48.0        19.0   \n8         NNW          80.0         SE  ...        42.0         9.0   \n9           W          28.0          S  ...        58.0        27.0   \n\n  Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday  \\\n0      1007.7      1007.1      8.0     None    16.9    21.8        No   \n1      1010.6      1007.8     None     None    17.2    24.3        No   \n2      1007.6      1008.7     None      2.0    21.0    23.2        No   \n3      1017.6      1012.8     None     None    18.1    26.5        No   \n4      1010.8      1006.0      7.0      8.0    17.8    29.7        No   \n5      1009.2      1005.4     None     None    20.6    28.9        No   \n6      1009.6      1008.2      1.0     None    18.1    24.6        No   \n7      1013.4      1010.1     None     None    16.3    25.5        No   \n8      1008.9      1003.6     None     None    18.3    30.2        No   \n9      1007.0      1005.7     None     None    20.1    28.2       Yes   \n\n  RainTomorrow  \n0           No  \n1           No  \n2           No  \n3           No  \n4           No  \n5           No  \n6           No  \n7           No  \n8          Yes  \n9           No  \n\n[10 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>...</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2008-12-01</td>\n      <td>Albury</td>\n      <td>13.4</td>\n      <td>22.9</td>\n      <td>0.6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>W</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.7</td>\n      <td>1007.1</td>\n      <td>8.0</td>\n      <td>None</td>\n      <td>16.9</td>\n      <td>21.8</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2008-12-02</td>\n      <td>Albury</td>\n      <td>7.4</td>\n      <td>25.1</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WNW</td>\n      <td>44.0</td>\n      <td>NNW</td>\n      <td>...</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.6</td>\n      <td>1007.8</td>\n      <td>None</td>\n      <td>None</td>\n      <td>17.2</td>\n      <td>24.3</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2008-12-03</td>\n      <td>Albury</td>\n      <td>12.9</td>\n      <td>25.7</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WSW</td>\n      <td>46.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.6</td>\n      <td>1008.7</td>\n      <td>None</td>\n      <td>2.0</td>\n      <td>21.0</td>\n      <td>23.2</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2008-12-04</td>\n      <td>Albury</td>\n      <td>9.2</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NE</td>\n      <td>24.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.6</td>\n      <td>1012.8</td>\n      <td>None</td>\n      <td>None</td>\n      <td>18.1</td>\n      <td>26.5</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2008-12-05</td>\n      <td>Albury</td>\n      <td>17.5</td>\n      <td>32.3</td>\n      <td>1.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>W</td>\n      <td>41.0</td>\n      <td>ENE</td>\n      <td>...</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1010.8</td>\n      <td>1006.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>17.8</td>\n      <td>29.7</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2008-12-06</td>\n      <td>Albury</td>\n      <td>14.6</td>\n      <td>29.7</td>\n      <td>0.2</td>\n      <td>None</td>\n      <td>None</td>\n      <td>WNW</td>\n      <td>56.0</td>\n      <td>W</td>\n      <td>...</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.2</td>\n      <td>1005.4</td>\n      <td>None</td>\n      <td>None</td>\n      <td>20.6</td>\n      <td>28.9</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2008-12-07</td>\n      <td>Albury</td>\n      <td>14.3</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>W</td>\n      <td>50.0</td>\n      <td>SW</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.6</td>\n      <td>1008.2</td>\n      <td>1.0</td>\n      <td>None</td>\n      <td>18.1</td>\n      <td>24.6</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2008-12-08</td>\n      <td>Albury</td>\n      <td>7.7</td>\n      <td>26.7</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>W</td>\n      <td>35.0</td>\n      <td>SSE</td>\n      <td>...</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.4</td>\n      <td>1010.1</td>\n      <td>None</td>\n      <td>None</td>\n      <td>16.3</td>\n      <td>25.5</td>\n      <td>No</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2008-12-09</td>\n      <td>Albury</td>\n      <td>9.7</td>\n      <td>31.9</td>\n      <td>0.0</td>\n      <td>None</td>\n      <td>None</td>\n      <td>NNW</td>\n      <td>80.0</td>\n      <td>SE</td>\n      <td>...</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1008.9</td>\n      <td>1003.6</td>\n      <td>None</td>\n      <td>None</td>\n      <td>18.3</td>\n      <td>30.2</td>\n      <td>No</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2008-12-10</td>\n      <td>Albury</td>\n      <td>13.1</td>\n      <td>30.1</td>\n      <td>1.4</td>\n      <td>None</td>\n      <td>None</td>\n      <td>W</td>\n      <td>28.0</td>\n      <td>S</td>\n      <td>...</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.7</td>\n      <td>None</td>\n      <td>None</td>\n      <td>20.1</td>\n      <td>28.2</td>\n      <td>Yes</td>\n      <td>No</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"df[\"RainToday\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:44:10.635344Z","iopub.execute_input":"2025-04-30T05:44:10.635654Z","iopub.status.idle":"2025-04-30T05:44:10.653424Z","shell.execute_reply.started":"2025-04-30T05:44:10.635634Z","shell.execute_reply":"2025-04-30T05:44:10.652491Z"}},"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"RainToday\nNo     110319\nYes     31880\nName: count, dtype: int64"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"# Just to test a hunch.\n\nlen(df), len(df.dropna())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:39:42.308157Z","iopub.execute_input":"2025-04-30T05:39:42.308452Z","iopub.status.idle":"2025-04-30T05:39:42.449543Z","shell.execute_reply.started":"2025-04-30T05:39:42.308429Z","shell.execute_reply":"2025-04-30T05:39:42.448835Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"(145460, 56420)"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:25:28.521158Z","iopub.execute_input":"2025-04-30T05:25:28.521469Z","iopub.status.idle":"2025-04-30T05:25:28.529816Z","shell.execute_reply.started":"2025-04-30T05:25:28.521445Z","shell.execute_reply":"2025-04-30T05:25:28.528769Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Date             object\nLocation         object\nMinTemp          object\nMaxTemp          object\nRainfall         object\nEvaporation      object\nSunshine         object\nWindGustDir      object\nWindGustSpeed    object\nWindDir9am       object\nWindDir3pm       object\nWindSpeed9am     object\nWindSpeed3pm     object\nHumidity9am      object\nHumidity3pm      object\nPressure9am      object\nPressure3pm      object\nCloud9am         object\nCloud3pm         object\nTemp9am          object\nTemp3pm          object\nRainToday        object\nRainTomorrow     object\ndtype: object"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"categorical = [col for col in df.columns if df[col].dtypes == 'O']\ncategorical","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:39:45.342582Z","iopub.execute_input":"2025-04-30T05:39:45.342913Z","iopub.status.idle":"2025-04-30T05:39:45.349560Z","shell.execute_reply.started":"2025-04-30T05:39:45.342891Z","shell.execute_reply":"2025-04-30T05:39:45.348664Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"['Date',\n 'Location',\n 'MinTemp',\n 'MaxTemp',\n 'Rainfall',\n 'Evaporation',\n 'Sunshine',\n 'WindGustDir',\n 'WindGustSpeed',\n 'WindDir9am',\n 'WindDir3pm',\n 'WindSpeed9am',\n 'WindSpeed3pm',\n 'Humidity9am',\n 'Humidity3pm',\n 'Pressure9am',\n 'Pressure3pm',\n 'Cloud9am',\n 'Cloud3pm',\n 'Temp9am',\n 'Temp3pm',\n 'RainToday',\n 'RainTomorrow']"},"metadata":{}}],"execution_count":78},{"cell_type":"markdown","source":"The raw data requires some work; some features that are clearly numericals are not registered as such.","metadata":{}},{"cell_type":"code","source":"non_numericals = [\"Date\", \"Location\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\", \"RainToday\", \"RainTomorrow\"]\n\n#df = df.replace(np.nan, None) # for ease of work later on\nfor col in df.columns:\n    if col not in non_numericals:\n        if df[col].dtype != np.float16:\n            df[col] = df[col].astype(np.float16)\n\n# We cannot convert RainToday and RainTomorrow directly to boolean\n# because \"Yes\", \"No\" does not clearnly become True, False\n# hence the use of a dictionary and apply()\nreplacement_dict = {\n    \"Yes\": True,\n    \"No\": False,\n    True: True, # to make rerunning this cell not throw errors\n    False: False,\n    None: False,\n}\nfor col in [\"RainToday\", \"RainTomorrow\"]:\n    df[col] = df[col].apply(lambda input: replacement_dict[input])\n    df[col] = df[col].astype(bool) # Convert bool to integer 0/1; not doing so causes NaN values to appear in the train-test-s-lot partitions\n    #df[col] = df[col].astype(np.int8)\ndf.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:04.255756Z","iopub.execute_input":"2025-04-30T05:47:04.256043Z","iopub.status.idle":"2025-04-30T05:47:04.436051Z","shell.execute_reply.started":"2025-04-30T05:47:04.256024Z","shell.execute_reply":"2025-04-30T05:47:04.435207Z"}},"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"Date              object\nLocation          object\nMinTemp          float16\nMaxTemp          float16\nRainfall         float16\nEvaporation      float16\nSunshine         float16\nWindGustDir       object\nWindGustSpeed    float16\nWindDir9am        object\nWindDir3pm        object\nWindSpeed9am     float16\nWindSpeed3pm     float16\nHumidity9am      float16\nHumidity3pm      float16\nPressure9am      float16\nPressure3pm      float16\nCloud9am         float16\nCloud3pm         float16\nTemp9am          float16\nTemp3pm          float16\nRainToday           bool\nRainTomorrow        bool\ndtype: object"},"metadata":{}}],"execution_count":105},{"cell_type":"code","source":"df[\"RainToday\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:22.119279Z","iopub.execute_input":"2025-04-30T05:47:22.119573Z","iopub.status.idle":"2025-04-30T05:47:22.127234Z","shell.execute_reply.started":"2025-04-30T05:47:22.119552Z","shell.execute_reply":"2025-04-30T05:47:22.126372Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"RainToday\nFalse    113580\nTrue      31880\nName: count, dtype: int64"},"metadata":{}}],"execution_count":106},{"cell_type":"markdown","source":"This looks a lot better - the features that should be numbers are now numbers. Let's move on.","metadata":{}},{"cell_type":"code","source":"df[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf = df.assign( # Replace the date with day, month, year.\n    Year=df[\"Date\"].dt.year,\n    Month=df[\"Date\"].dt.month,\n    Day=df[\"Date\"].dt.day,\n)\ndf.drop('Date', axis=1, inplace=True)\n#df_dropped2[['Day', 'Month', 'Year']] = pd.DataFrame(df_dropped2['Date'].dt.day, df_dropped2['Date'].dt.month, df_dropped2['Date'].dt.year)\ndf.head(10)\n#df_dropped2['Date'].dt.day","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:26.617640Z","iopub.execute_input":"2025-04-30T05:47:26.618417Z","iopub.status.idle":"2025-04-30T05:47:26.696303Z","shell.execute_reply.started":"2025-04-30T05:47:26.618389Z","shell.execute_reply":"2025-04-30T05:47:26.695384Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n","output_type":"stream"},{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"  Location    MinTemp    MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n0   Albury  13.398438  22.906250  0.600098          NaN       NaN           W   \n1   Albury   7.398438  25.093750  0.000000          NaN       NaN         WNW   \n2   Albury  12.898438  25.703125  0.000000          NaN       NaN         WSW   \n3   Albury   9.203125  28.000000  0.000000          NaN       NaN          NE   \n4   Albury  17.500000  32.312500  1.000000          NaN       NaN           W   \n5   Albury  14.601562  29.703125  0.199951          NaN       NaN         WNW   \n6   Albury  14.296875  25.000000  0.000000          NaN       NaN           W   \n7   Albury   7.699219  26.703125  0.000000          NaN       NaN           W   \n8   Albury   9.703125  31.906250  0.000000          NaN       NaN         NNW   \n9   Albury  13.101562  30.093750  1.400391          NaN       NaN           W   \n\n   WindGustSpeed WindDir9am WindDir3pm  ...  Pressure3pm  Cloud9am  Cloud3pm  \\\n0           44.0          W        WNW  ...       1007.0       8.0       NaN   \n1           44.0        NNW        WSW  ...       1008.0       NaN       NaN   \n2           46.0          W        WSW  ...       1008.5       NaN       2.0   \n3           24.0         SE          E  ...       1013.0       NaN       NaN   \n4           41.0        ENE         NW  ...       1006.0       7.0       8.0   \n5           56.0          W          W  ...       1005.5       NaN       NaN   \n6           50.0         SW          W  ...       1008.0       1.0       NaN   \n7           35.0        SSE          W  ...       1010.0       NaN       NaN   \n8           80.0         SE         NW  ...       1003.5       NaN       NaN   \n9           28.0          S        SSE  ...       1005.5       NaN       NaN   \n\n     Temp9am    Temp3pm  RainToday  RainTomorrow  Year  Month  Day  \n0  16.906250  21.796875      False         False  2008     12    1  \n1  17.203125  24.296875      False         False  2008     12    2  \n2  21.000000  23.203125      False         False  2008     12    3  \n3  18.093750  26.500000      False         False  2008     12    4  \n4  17.796875  29.703125      False         False  2008     12    5  \n5  20.593750  28.906250      False         False  2008     12    6  \n6  18.093750  24.593750      False         False  2008     12    7  \n7  16.296875  25.500000      False         False  2008     12    8  \n8  18.296875  30.203125      False          True  2008     12    9  \n9  20.093750  28.203125       True         False  2008     12   10  \n\n[10 rows x 25 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Location</th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>...</th>\n      <th>Pressure3pm</th>\n      <th>Cloud9am</th>\n      <th>Cloud3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albury</td>\n      <td>13.398438</td>\n      <td>22.906250</td>\n      <td>0.600098</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>WNW</td>\n      <td>...</td>\n      <td>1007.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>16.906250</td>\n      <td>21.796875</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albury</td>\n      <td>7.398438</td>\n      <td>25.093750</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WNW</td>\n      <td>44.0</td>\n      <td>NNW</td>\n      <td>WSW</td>\n      <td>...</td>\n      <td>1008.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>17.203125</td>\n      <td>24.296875</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albury</td>\n      <td>12.898438</td>\n      <td>25.703125</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WSW</td>\n      <td>46.0</td>\n      <td>W</td>\n      <td>WSW</td>\n      <td>...</td>\n      <td>1008.5</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>21.000000</td>\n      <td>23.203125</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albury</td>\n      <td>9.203125</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NE</td>\n      <td>24.0</td>\n      <td>SE</td>\n      <td>E</td>\n      <td>...</td>\n      <td>1013.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18.093750</td>\n      <td>26.500000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albury</td>\n      <td>17.500000</td>\n      <td>32.312500</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>41.0</td>\n      <td>ENE</td>\n      <td>NW</td>\n      <td>...</td>\n      <td>1006.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>17.796875</td>\n      <td>29.703125</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Albury</td>\n      <td>14.601562</td>\n      <td>29.703125</td>\n      <td>0.199951</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WNW</td>\n      <td>56.0</td>\n      <td>W</td>\n      <td>W</td>\n      <td>...</td>\n      <td>1005.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.593750</td>\n      <td>28.906250</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Albury</td>\n      <td>14.296875</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>50.0</td>\n      <td>SW</td>\n      <td>W</td>\n      <td>...</td>\n      <td>1008.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>18.093750</td>\n      <td>24.593750</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Albury</td>\n      <td>7.699219</td>\n      <td>26.703125</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>35.0</td>\n      <td>SSE</td>\n      <td>W</td>\n      <td>...</td>\n      <td>1010.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>16.296875</td>\n      <td>25.500000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Albury</td>\n      <td>9.703125</td>\n      <td>31.906250</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NNW</td>\n      <td>80.0</td>\n      <td>SE</td>\n      <td>NW</td>\n      <td>...</td>\n      <td>1003.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>18.296875</td>\n      <td>30.203125</td>\n      <td>False</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Albury</td>\n      <td>13.101562</td>\n      <td>30.093750</td>\n      <td>1.400391</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>W</td>\n      <td>28.0</td>\n      <td>S</td>\n      <td>SSE</td>\n      <td>...</td>\n      <td>1005.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20.093750</td>\n      <td>28.203125</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 25 columns</p>\n</div>"},"metadata":{}}],"execution_count":107},{"cell_type":"code","source":"len(df), df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:27:35.043208Z","iopub.execute_input":"2025-04-30T05:27:35.043634Z","iopub.status.idle":"2025-04-30T05:27:35.107421Z","shell.execute_reply.started":"2025-04-30T05:27:35.043580Z","shell.execute_reply":"2025-04-30T05:27:35.106444Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(145460,\n Location             0\n MinTemp           1485\n MaxTemp           1261\n Rainfall          3261\n Evaporation      62790\n Sunshine         69835\n WindGustDir      10326\n WindGustSpeed    10263\n WindDir9am       10566\n WindDir3pm        4228\n WindSpeed9am      1767\n WindSpeed3pm      3062\n Humidity9am       2654\n Humidity3pm       4507\n Pressure9am      15065\n Pressure3pm      15028\n Cloud9am         55888\n Cloud3pm         59358\n Temp9am           1767\n Temp3pm           3609\n RainToday            0\n RainTomorrow         0\n Year                 0\n Month                0\n Day                  0\n dtype: int64)"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## Missing Data\n\nAlmost every attribute (besides location and date) have some amount of missing values. Some, like MinTemp or MaxTemp, only have a small proportion of missing values (around 1% of all entries). Others, such as Evaporation and Sunshine, have many missing values (upwards of 48%).\n\n## Initial Approach: drop some, inpute some\n\nWe intended to keep attributes with no more than around 10% missing entries and discard the ones with higher missing entries (Evaporation, Sunshine, Cloud9am, Cloud3pm).I do not plan on imputing values for these removed features because, with this many missing entries, there is the possibility that the data we have does not reflect the actual data.\n\nWe will also drop Location, since I don't think those will be particularly helpful for classification work. I will convert Date into model-friendly day, month, year features later, as well as one-hot encode some of the categoricals, later.","metadata":{}},{"cell_type":"code","source":"drop_cols = [\"Location\", \"Cloud9am\", \"Cloud3pm\", \"Evaporation\", \"Sunshine\"]\ndf_dropped = df.copy()\ndf_dropped.drop(columns=drop_cols, inplace=True)\ndf_dropped.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:30.837967Z","iopub.execute_input":"2025-04-30T05:47:30.838582Z","iopub.status.idle":"2025-04-30T05:47:30.871278Z","shell.execute_reply.started":"2025-04-30T05:47:30.838559Z","shell.execute_reply":"2025-04-30T05:47:30.870391Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"     MinTemp    MaxTemp  Rainfall WindGustDir  WindGustSpeed WindDir9am  \\\n0  13.398438  22.906250  0.600098           W           44.0          W   \n1   7.398438  25.093750  0.000000         WNW           44.0        NNW   \n2  12.898438  25.703125  0.000000         WSW           46.0          W   \n3   9.203125  28.000000  0.000000          NE           24.0         SE   \n4  17.500000  32.312500  1.000000           W           41.0        ENE   \n5  14.601562  29.703125  0.199951         WNW           56.0          W   \n6  14.296875  25.000000  0.000000           W           50.0         SW   \n7   7.699219  26.703125  0.000000           W           35.0        SSE   \n8   9.703125  31.906250  0.000000         NNW           80.0         SE   \n9  13.101562  30.093750  1.400391           W           28.0          S   \n\n  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n0        WNW          20.0          24.0         71.0         22.0   \n1        WSW           4.0          22.0         44.0         25.0   \n2        WSW          19.0          26.0         38.0         30.0   \n3          E          11.0           9.0         45.0         16.0   \n4         NW           7.0          20.0         82.0         33.0   \n5          W          19.0          24.0         55.0         23.0   \n6          W          20.0          24.0         49.0         19.0   \n7          W           6.0          17.0         48.0         19.0   \n8         NW           7.0          28.0         42.0          9.0   \n9        SSE          15.0          11.0         58.0         27.0   \n\n   Pressure9am  Pressure3pm    Temp9am    Temp3pm  RainToday  RainTomorrow  \\\n0       1007.5       1007.0  16.906250  21.796875      False         False   \n1       1010.5       1008.0  17.203125  24.296875      False         False   \n2       1007.5       1008.5  21.000000  23.203125      False         False   \n3       1017.5       1013.0  18.093750  26.500000      False         False   \n4       1011.0       1006.0  17.796875  29.703125      False         False   \n5       1009.0       1005.5  20.593750  28.906250      False         False   \n6       1009.5       1008.0  18.093750  24.593750      False         False   \n7       1013.5       1010.0  16.296875  25.500000      False         False   \n8       1009.0       1003.5  18.296875  30.203125      False          True   \n9       1007.0       1005.5  20.093750  28.203125       True         False   \n\n   Year  Month  Day  \n0  2008     12    1  \n1  2008     12    2  \n2  2008     12    3  \n3  2008     12    4  \n4  2008     12    5  \n5  2008     12    6  \n6  2008     12    7  \n7  2008     12    8  \n8  2008     12    9  \n9  2008     12   10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.398438</td>\n      <td>22.906250</td>\n      <td>0.600098</td>\n      <td>W</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>WNW</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.5</td>\n      <td>1007.0</td>\n      <td>16.906250</td>\n      <td>21.796875</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.398438</td>\n      <td>25.093750</td>\n      <td>0.000000</td>\n      <td>WNW</td>\n      <td>44.0</td>\n      <td>NNW</td>\n      <td>WSW</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.5</td>\n      <td>1008.0</td>\n      <td>17.203125</td>\n      <td>24.296875</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.898438</td>\n      <td>25.703125</td>\n      <td>0.000000</td>\n      <td>WSW</td>\n      <td>46.0</td>\n      <td>W</td>\n      <td>WSW</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.5</td>\n      <td>1008.5</td>\n      <td>21.000000</td>\n      <td>23.203125</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.203125</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>NE</td>\n      <td>24.0</td>\n      <td>SE</td>\n      <td>E</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.5</td>\n      <td>1013.0</td>\n      <td>18.093750</td>\n      <td>26.500000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.500000</td>\n      <td>32.312500</td>\n      <td>1.000000</td>\n      <td>W</td>\n      <td>41.0</td>\n      <td>ENE</td>\n      <td>NW</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1011.0</td>\n      <td>1006.0</td>\n      <td>17.796875</td>\n      <td>29.703125</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.601562</td>\n      <td>29.703125</td>\n      <td>0.199951</td>\n      <td>WNW</td>\n      <td>56.0</td>\n      <td>W</td>\n      <td>W</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.0</td>\n      <td>1005.5</td>\n      <td>20.593750</td>\n      <td>28.906250</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.296875</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>W</td>\n      <td>50.0</td>\n      <td>SW</td>\n      <td>W</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.5</td>\n      <td>1008.0</td>\n      <td>18.093750</td>\n      <td>24.593750</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.699219</td>\n      <td>26.703125</td>\n      <td>0.000000</td>\n      <td>W</td>\n      <td>35.0</td>\n      <td>SSE</td>\n      <td>W</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.5</td>\n      <td>1010.0</td>\n      <td>16.296875</td>\n      <td>25.500000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.703125</td>\n      <td>31.906250</td>\n      <td>0.000000</td>\n      <td>NNW</td>\n      <td>80.0</td>\n      <td>SE</td>\n      <td>NW</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1009.0</td>\n      <td>1003.5</td>\n      <td>18.296875</td>\n      <td>30.203125</td>\n      <td>False</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.101562</td>\n      <td>30.093750</td>\n      <td>1.400391</td>\n      <td>W</td>\n      <td>28.0</td>\n      <td>S</td>\n      <td>SSE</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.5</td>\n      <td>20.093750</td>\n      <td>28.203125</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":108},{"cell_type":"markdown","source":"We will be dropping rows that do not contain RainToday or Rainfall, since RainToday is a training target and Rainfall is intricately linked to it. I do not intend to fill in missing RainToday values since that would be basically making up targets, which could have unforeseen consequences on the model's performance.","metadata":{}},{"cell_type":"code","source":"# Just to test a hunch.\n\nlen(df_dropped), len(df_dropped.dropna())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:40:14.492969Z","iopub.execute_input":"2025-04-30T05:40:14.493281Z","iopub.status.idle":"2025-04-30T05:40:14.534743Z","shell.execute_reply.started":"2025-04-30T05:40:14.493258Z","shell.execute_reply":"2025-04-30T05:40:14.533837Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"(145460, 113679)"},"metadata":{}}],"execution_count":82},{"cell_type":"markdown","source":"The \"Date\" feature is in a datetime format, which cannot be used for model training. I will decompose it into year, month, day features.","metadata":{}},{"cell_type":"code","source":"df_dropped2 = df_dropped.copy()\ndf_dropped2 = df_dropped2[pd.notna(df_dropped[\"RainToday\"])]\ndf_dropped2.head(10)\n#df_dropped2['Date'].dt.day","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:34.237365Z","iopub.execute_input":"2025-04-30T05:47:34.238101Z","iopub.status.idle":"2025-04-30T05:47:34.268586Z","shell.execute_reply.started":"2025-04-30T05:47:34.238066Z","shell.execute_reply":"2025-04-30T05:47:34.267807Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"     MinTemp    MaxTemp  Rainfall WindGustDir  WindGustSpeed WindDir9am  \\\n0  13.398438  22.906250  0.600098           W           44.0          W   \n1   7.398438  25.093750  0.000000         WNW           44.0        NNW   \n2  12.898438  25.703125  0.000000         WSW           46.0          W   \n3   9.203125  28.000000  0.000000          NE           24.0         SE   \n4  17.500000  32.312500  1.000000           W           41.0        ENE   \n5  14.601562  29.703125  0.199951         WNW           56.0          W   \n6  14.296875  25.000000  0.000000           W           50.0         SW   \n7   7.699219  26.703125  0.000000           W           35.0        SSE   \n8   9.703125  31.906250  0.000000         NNW           80.0         SE   \n9  13.101562  30.093750  1.400391           W           28.0          S   \n\n  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n0        WNW          20.0          24.0         71.0         22.0   \n1        WSW           4.0          22.0         44.0         25.0   \n2        WSW          19.0          26.0         38.0         30.0   \n3          E          11.0           9.0         45.0         16.0   \n4         NW           7.0          20.0         82.0         33.0   \n5          W          19.0          24.0         55.0         23.0   \n6          W          20.0          24.0         49.0         19.0   \n7          W           6.0          17.0         48.0         19.0   \n8         NW           7.0          28.0         42.0          9.0   \n9        SSE          15.0          11.0         58.0         27.0   \n\n   Pressure9am  Pressure3pm    Temp9am    Temp3pm  RainToday  RainTomorrow  \\\n0       1007.5       1007.0  16.906250  21.796875      False         False   \n1       1010.5       1008.0  17.203125  24.296875      False         False   \n2       1007.5       1008.5  21.000000  23.203125      False         False   \n3       1017.5       1013.0  18.093750  26.500000      False         False   \n4       1011.0       1006.0  17.796875  29.703125      False         False   \n5       1009.0       1005.5  20.593750  28.906250      False         False   \n6       1009.5       1008.0  18.093750  24.593750      False         False   \n7       1013.5       1010.0  16.296875  25.500000      False         False   \n8       1009.0       1003.5  18.296875  30.203125      False          True   \n9       1007.0       1005.5  20.093750  28.203125       True         False   \n\n   Year  Month  Day  \n0  2008     12    1  \n1  2008     12    2  \n2  2008     12    3  \n3  2008     12    4  \n4  2008     12    5  \n5  2008     12    6  \n6  2008     12    7  \n7  2008     12    8  \n8  2008     12    9  \n9  2008     12   10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.398438</td>\n      <td>22.906250</td>\n      <td>0.600098</td>\n      <td>W</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>WNW</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.5</td>\n      <td>1007.0</td>\n      <td>16.906250</td>\n      <td>21.796875</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.398438</td>\n      <td>25.093750</td>\n      <td>0.000000</td>\n      <td>WNW</td>\n      <td>44.0</td>\n      <td>NNW</td>\n      <td>WSW</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.5</td>\n      <td>1008.0</td>\n      <td>17.203125</td>\n      <td>24.296875</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.898438</td>\n      <td>25.703125</td>\n      <td>0.000000</td>\n      <td>WSW</td>\n      <td>46.0</td>\n      <td>W</td>\n      <td>WSW</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.5</td>\n      <td>1008.5</td>\n      <td>21.000000</td>\n      <td>23.203125</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.203125</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>NE</td>\n      <td>24.0</td>\n      <td>SE</td>\n      <td>E</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.5</td>\n      <td>1013.0</td>\n      <td>18.093750</td>\n      <td>26.500000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.500000</td>\n      <td>32.312500</td>\n      <td>1.000000</td>\n      <td>W</td>\n      <td>41.0</td>\n      <td>ENE</td>\n      <td>NW</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1011.0</td>\n      <td>1006.0</td>\n      <td>17.796875</td>\n      <td>29.703125</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.601562</td>\n      <td>29.703125</td>\n      <td>0.199951</td>\n      <td>WNW</td>\n      <td>56.0</td>\n      <td>W</td>\n      <td>W</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.0</td>\n      <td>1005.5</td>\n      <td>20.593750</td>\n      <td>28.906250</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.296875</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>W</td>\n      <td>50.0</td>\n      <td>SW</td>\n      <td>W</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.5</td>\n      <td>1008.0</td>\n      <td>18.093750</td>\n      <td>24.593750</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.699219</td>\n      <td>26.703125</td>\n      <td>0.000000</td>\n      <td>W</td>\n      <td>35.0</td>\n      <td>SSE</td>\n      <td>W</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.5</td>\n      <td>1010.0</td>\n      <td>16.296875</td>\n      <td>25.500000</td>\n      <td>False</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.703125</td>\n      <td>31.906250</td>\n      <td>0.000000</td>\n      <td>NNW</td>\n      <td>80.0</td>\n      <td>SE</td>\n      <td>NW</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1009.0</td>\n      <td>1003.5</td>\n      <td>18.296875</td>\n      <td>30.203125</td>\n      <td>False</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.101562</td>\n      <td>30.093750</td>\n      <td>1.400391</td>\n      <td>W</td>\n      <td>28.0</td>\n      <td>S</td>\n      <td>SSE</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.5</td>\n      <td>20.093750</td>\n      <td>28.203125</td>\n      <td>True</td>\n      <td>False</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"pd.unique(df_dropped2[\"RainToday\"]),df_dropped2[\"RainToday\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:36.638121Z","iopub.execute_input":"2025-04-30T05:47:36.638406Z","iopub.status.idle":"2025-04-30T05:47:36.646337Z","shell.execute_reply.started":"2025-04-30T05:47:36.638386Z","shell.execute_reply":"2025-04-30T05:47:36.645656Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"(array([False,  True]),\n RainToday\n False    113580\n True      31880\n Name: count, dtype: int64)"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"df_dropped2.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:40:22.976111Z","iopub.execute_input":"2025-04-30T05:40:22.976830Z","iopub.status.idle":"2025-04-30T05:40:23.027080Z","shell.execute_reply.started":"2025-04-30T05:40:22.976799Z","shell.execute_reply":"2025-04-30T05:40:23.026223Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"MinTemp           1485\nMaxTemp           1261\nRainfall          3261\nWindGustDir      10326\nWindGustSpeed    10263\nWindDir9am       10566\nWindDir3pm        4228\nWindSpeed9am      1767\nWindSpeed3pm      3062\nHumidity9am       2654\nHumidity3pm       4507\nPressure9am      15065\nPressure3pm      15028\nTemp9am           1767\nTemp3pm           3609\nRainToday            0\nRainTomorrow         0\nYear                 0\nMonth                0\nDay                  0\ndtype: int64"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"# Just to test a hunch.\n\nlen(df_dropped2), len(df_dropped2.dropna()), len(df_dropped2.dropna())/len(df_dropped2)\n# We keep 78.1% of the initial data with this reduced drop. Let's see if 113k rows is enough to train a good model.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:38:48.286858Z","iopub.execute_input":"2025-04-30T05:38:48.287167Z","iopub.status.idle":"2025-04-30T05:38:48.363356Z","shell.execute_reply.started":"2025-04-30T05:38:48.287146Z","shell.execute_reply":"2025-04-30T05:38:48.362596Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"(145460, 113679, 0.7815138182318163)"},"metadata":{}}],"execution_count":71},{"cell_type":"markdown","source":"## Remove Missing Values\n\nThe main approach we had in mind was to remove all rows with missing values, using only the remainder for training + validation + testing. This will discard roughly 1/5 of the data, leaving 113679 rows to carry out supervised predictions from. Hopefully this will be enough training data to learn on.","metadata":{}},{"cell_type":"code","source":"pd.unique(df_dropped2[\"RainToday\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:40:26.411586Z","iopub.execute_input":"2025-04-30T05:40:26.411903Z","iopub.status.idle":"2025-04-30T05:40:26.418519Z","shell.execute_reply.started":"2025-04-30T05:40:26.411881Z","shell.execute_reply":"2025-04-30T05:40:26.417662Z"}},"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"array([ True, False])"},"metadata":{}}],"execution_count":86},{"cell_type":"code","source":"df_dropped2.dropna(axis=0, inplace=True, how=\"any\") # Approach: use only entries with no missing values\ndf_dropped2.dtypes, df_dropped2.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:42.509698Z","iopub.execute_input":"2025-04-30T05:47:42.510217Z","iopub.status.idle":"2025-04-30T05:47:42.593651Z","shell.execute_reply.started":"2025-04-30T05:47:42.510188Z","shell.execute_reply":"2025-04-30T05:47:42.592913Z"}},"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"(MinTemp          float16\n MaxTemp          float16\n Rainfall         float16\n WindGustDir       object\n WindGustSpeed    float16\n WindDir9am        object\n WindDir3pm        object\n WindSpeed9am     float16\n WindSpeed3pm     float16\n Humidity9am      float16\n Humidity3pm      float16\n Pressure9am      float16\n Pressure3pm      float16\n Temp9am          float16\n Temp3pm          float16\n RainToday           bool\n RainTomorrow        bool\n Year               int32\n Month              int32\n Day                int32\n dtype: object,\n MinTemp          0\n MaxTemp          0\n Rainfall         0\n WindGustDir      0\n WindGustSpeed    0\n WindDir9am       0\n WindDir3pm       0\n WindSpeed9am     0\n WindSpeed3pm     0\n Humidity9am      0\n Humidity3pm      0\n Pressure9am      0\n Pressure3pm      0\n Temp9am          0\n Temp3pm          0\n RainToday        0\n RainTomorrow     0\n Year             0\n Month            0\n Day              0\n dtype: int64)"},"metadata":{}}],"execution_count":111},{"cell_type":"code","source":"pd.unique(df_dropped2[\"RainToday\"]), df_dropped2[\"RainToday\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:45.051693Z","iopub.execute_input":"2025-04-30T05:47:45.052054Z","iopub.status.idle":"2025-04-30T05:47:45.059732Z","shell.execute_reply.started":"2025-04-30T05:47:45.052030Z","shell.execute_reply":"2025-04-30T05:47:45.058965Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"(array([False,  True]),\n RainToday\n False    88066\n True     25613\n Name: count, dtype: int64)"},"metadata":{}}],"execution_count":112},{"cell_type":"code","source":"df_dropped2.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:31:15.298325Z","iopub.execute_input":"2025-04-30T05:31:15.298644Z","iopub.status.idle":"2025-04-30T05:31:15.304068Z","shell.execute_reply.started":"2025-04-30T05:31:15.298620Z","shell.execute_reply":"2025-04-30T05:31:15.303368Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Index(['MinTemp', 'MaxTemp', 'Rainfall', 'WindGustDir', 'WindGustSpeed',\n       'WindDir9am', 'WindDir3pm', 'WindSpeed9am', 'WindSpeed3pm',\n       'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am',\n       'Temp3pm', 'RainToday', 'RainTomorrow', 'Year', 'Month', 'Day'],\n      dtype='object')"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"df_dropped2.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:31:17.982005Z","iopub.execute_input":"2025-04-30T05:31:17.982663Z","iopub.status.idle":"2025-04-30T05:31:18.003922Z","shell.execute_reply.started":"2025-04-30T05:31:17.982633Z","shell.execute_reply":"2025-04-30T05:31:18.003043Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"     MinTemp    MaxTemp  Rainfall WindGustDir  WindGustSpeed WindDir9am  \\\n0  13.398438  22.906250  0.600098           W           44.0          W   \n1   7.398438  25.093750  0.000000         WNW           44.0        NNW   \n2  12.898438  25.703125  0.000000         WSW           46.0          W   \n3   9.203125  28.000000  0.000000          NE           24.0         SE   \n4  17.500000  32.312500  1.000000           W           41.0        ENE   \n5  14.601562  29.703125  0.199951         WNW           56.0          W   \n6  14.296875  25.000000  0.000000           W           50.0         SW   \n7   7.699219  26.703125  0.000000           W           35.0        SSE   \n8   9.703125  31.906250  0.000000         NNW           80.0         SE   \n9  13.101562  30.093750  1.400391           W           28.0          S   \n\n  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  \\\n0        WNW          20.0          24.0         71.0         22.0   \n1        WSW           4.0          22.0         44.0         25.0   \n2        WSW          19.0          26.0         38.0         30.0   \n3          E          11.0           9.0         45.0         16.0   \n4         NW           7.0          20.0         82.0         33.0   \n5          W          19.0          24.0         55.0         23.0   \n6          W          20.0          24.0         49.0         19.0   \n7          W           6.0          17.0         48.0         19.0   \n8         NW           7.0          28.0         42.0          9.0   \n9        SSE          15.0          11.0         58.0         27.0   \n\n   Pressure9am  Pressure3pm    Temp9am    Temp3pm  RainToday  RainTomorrow  \\\n0       1007.5       1007.0  16.906250  21.796875       True          True   \n1       1010.5       1008.0  17.203125  24.296875       True          True   \n2       1007.5       1008.5  21.000000  23.203125       True          True   \n3       1017.5       1013.0  18.093750  26.500000       True          True   \n4       1011.0       1006.0  17.796875  29.703125       True          True   \n5       1009.0       1005.5  20.593750  28.906250       True          True   \n6       1009.5       1008.0  18.093750  24.593750       True          True   \n7       1013.5       1010.0  16.296875  25.500000       True          True   \n8       1009.0       1003.5  18.296875  30.203125       True          True   \n9       1007.0       1005.5  20.093750  28.203125       True          True   \n\n   Year  Month  Day  \n0  2008     12    1  \n1  2008     12    2  \n2  2008     12    3  \n3  2008     12    4  \n4  2008     12    5  \n5  2008     12    6  \n6  2008     12    7  \n7  2008     12    8  \n8  2008     12    9  \n9  2008     12   10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>WindGustDir</th>\n      <th>WindGustSpeed</th>\n      <th>WindDir9am</th>\n      <th>WindDir3pm</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>Temp9am</th>\n      <th>Temp3pm</th>\n      <th>RainToday</th>\n      <th>RainTomorrow</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.398438</td>\n      <td>22.906250</td>\n      <td>0.600098</td>\n      <td>W</td>\n      <td>44.0</td>\n      <td>W</td>\n      <td>WNW</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.5</td>\n      <td>1007.0</td>\n      <td>16.906250</td>\n      <td>21.796875</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.398438</td>\n      <td>25.093750</td>\n      <td>0.000000</td>\n      <td>WNW</td>\n      <td>44.0</td>\n      <td>NNW</td>\n      <td>WSW</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.5</td>\n      <td>1008.0</td>\n      <td>17.203125</td>\n      <td>24.296875</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.898438</td>\n      <td>25.703125</td>\n      <td>0.000000</td>\n      <td>WSW</td>\n      <td>46.0</td>\n      <td>W</td>\n      <td>WSW</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.5</td>\n      <td>1008.5</td>\n      <td>21.000000</td>\n      <td>23.203125</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.203125</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>NE</td>\n      <td>24.0</td>\n      <td>SE</td>\n      <td>E</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.5</td>\n      <td>1013.0</td>\n      <td>18.093750</td>\n      <td>26.500000</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.500000</td>\n      <td>32.312500</td>\n      <td>1.000000</td>\n      <td>W</td>\n      <td>41.0</td>\n      <td>ENE</td>\n      <td>NW</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1011.0</td>\n      <td>1006.0</td>\n      <td>17.796875</td>\n      <td>29.703125</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.601562</td>\n      <td>29.703125</td>\n      <td>0.199951</td>\n      <td>WNW</td>\n      <td>56.0</td>\n      <td>W</td>\n      <td>W</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.0</td>\n      <td>1005.5</td>\n      <td>20.593750</td>\n      <td>28.906250</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.296875</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>W</td>\n      <td>50.0</td>\n      <td>SW</td>\n      <td>W</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.5</td>\n      <td>1008.0</td>\n      <td>18.093750</td>\n      <td>24.593750</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.699219</td>\n      <td>26.703125</td>\n      <td>0.000000</td>\n      <td>W</td>\n      <td>35.0</td>\n      <td>SSE</td>\n      <td>W</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.5</td>\n      <td>1010.0</td>\n      <td>16.296875</td>\n      <td>25.500000</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.703125</td>\n      <td>31.906250</td>\n      <td>0.000000</td>\n      <td>NNW</td>\n      <td>80.0</td>\n      <td>SE</td>\n      <td>NW</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1009.0</td>\n      <td>1003.5</td>\n      <td>18.296875</td>\n      <td>30.203125</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.101562</td>\n      <td>30.093750</td>\n      <td>1.400391</td>\n      <td>W</td>\n      <td>28.0</td>\n      <td>S</td>\n      <td>SSE</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.5</td>\n      <td>20.093750</td>\n      <td>28.203125</td>\n      <td>True</td>\n      <td>True</td>\n      <td>2008</td>\n      <td>12</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"We cannot train models on features with values \"Albury\", \"Adelaide\", and the likes. This is not a natural language processing problem so we do not need to use any embedding layers. Instead we will one-hot encode the categorical features.","metadata":{}},{"cell_type":"code","source":"df_onehot = df_dropped2\nfor categorical in [\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]:\n    df_onehot = pd.concat([df_onehot, pd.get_dummies(df_onehot[categorical], prefix=categorical)], axis=1)\n    df_onehot.drop(columns=categorical, inplace=True)\ndf_onehot.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:49.937871Z","iopub.execute_input":"2025-04-30T05:47:49.938175Z","iopub.status.idle":"2025-04-30T05:47:50.017868Z","shell.execute_reply.started":"2025-04-30T05:47:49.938153Z","shell.execute_reply":"2025-04-30T05:47:50.016970Z"}},"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"     MinTemp    MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  WindSpeed3pm  \\\n0  13.398438  22.906250  0.600098           44.0          20.0          24.0   \n1   7.398438  25.093750  0.000000           44.0           4.0          22.0   \n2  12.898438  25.703125  0.000000           46.0          19.0          26.0   \n3   9.203125  28.000000  0.000000           24.0          11.0           9.0   \n4  17.500000  32.312500  1.000000           41.0           7.0          20.0   \n5  14.601562  29.703125  0.199951           56.0          19.0          24.0   \n6  14.296875  25.000000  0.000000           50.0          20.0          24.0   \n7   7.699219  26.703125  0.000000           35.0           6.0          17.0   \n8   9.703125  31.906250  0.000000           80.0           7.0          28.0   \n9  13.101562  30.093750  1.400391           28.0          15.0          11.0   \n\n   Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  ...  WindDir3pm_NNW  \\\n0         71.0         22.0       1007.5       1007.0  ...           False   \n1         44.0         25.0       1010.5       1008.0  ...           False   \n2         38.0         30.0       1007.5       1008.5  ...           False   \n3         45.0         16.0       1017.5       1013.0  ...           False   \n4         82.0         33.0       1011.0       1006.0  ...           False   \n5         55.0         23.0       1009.0       1005.5  ...           False   \n6         49.0         19.0       1009.5       1008.0  ...           False   \n7         48.0         19.0       1013.5       1010.0  ...           False   \n8         42.0          9.0       1009.0       1003.5  ...           False   \n9         58.0         27.0       1007.0       1005.5  ...           False   \n\n   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n0          False         False          False           False           False   \n1          False         False          False           False           False   \n2          False         False          False           False           False   \n3          False         False          False           False           False   \n4           True         False          False           False           False   \n5          False         False          False           False           False   \n6          False         False          False           False           False   \n7          False         False          False           False           False   \n8           True         False          False           False           False   \n9          False         False          False            True           False   \n\n   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n0          False         False            True           False  \n1          False         False           False            True  \n2          False         False           False            True  \n3          False         False           False           False  \n4          False         False           False           False  \n5          False          True           False           False  \n6          False          True           False           False  \n7          False          True           False           False  \n8          False         False           False           False  \n9          False         False           False           False  \n\n[10 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>...</th>\n      <th>WindDir3pm_NNW</th>\n      <th>WindDir3pm_NW</th>\n      <th>WindDir3pm_S</th>\n      <th>WindDir3pm_SE</th>\n      <th>WindDir3pm_SSE</th>\n      <th>WindDir3pm_SSW</th>\n      <th>WindDir3pm_SW</th>\n      <th>WindDir3pm_W</th>\n      <th>WindDir3pm_WNW</th>\n      <th>WindDir3pm_WSW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.398438</td>\n      <td>22.906250</td>\n      <td>0.600098</td>\n      <td>44.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.5</td>\n      <td>1007.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.398438</td>\n      <td>25.093750</td>\n      <td>0.000000</td>\n      <td>44.0</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.5</td>\n      <td>1008.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.898438</td>\n      <td>25.703125</td>\n      <td>0.000000</td>\n      <td>46.0</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.5</td>\n      <td>1008.5</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.203125</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>24.0</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.5</td>\n      <td>1013.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.500000</td>\n      <td>32.312500</td>\n      <td>1.000000</td>\n      <td>41.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1011.0</td>\n      <td>1006.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.601562</td>\n      <td>29.703125</td>\n      <td>0.199951</td>\n      <td>56.0</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.0</td>\n      <td>1005.5</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.296875</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>50.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.5</td>\n      <td>1008.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.699219</td>\n      <td>26.703125</td>\n      <td>0.000000</td>\n      <td>35.0</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.5</td>\n      <td>1010.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.703125</td>\n      <td>31.906250</td>\n      <td>0.000000</td>\n      <td>80.0</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1009.0</td>\n      <td>1003.5</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.101562</td>\n      <td>30.093750</td>\n      <td>1.400391</td>\n      <td>28.0</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.5</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 65 columns</p>\n</div>"},"metadata":{}}],"execution_count":113},{"cell_type":"markdown","source":"## Final preparations\n\nWe finish up final preparations (standard scaling with scikit-learn).","metadata":{}},{"cell_type":"code","source":"for col in df_onehot.columns:\n    if df_onehot[col].dtype == bool and col not in [\"RainToday\", \"RainTomorrow\"]:\n        df_onehot[col] = df_onehot[col].astype(np.int8)\n# Convert bool to integer 0/1; not doing so causes NaN values to appear in the train-test-s-lot partitions\ndf_onehot.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:52.430634Z","iopub.execute_input":"2025-04-30T05:47:52.431896Z","iopub.status.idle":"2025-04-30T05:47:52.468199Z","shell.execute_reply.started":"2025-04-30T05:47:52.431865Z","shell.execute_reply":"2025-04-30T05:47:52.467358Z"}},"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"     MinTemp    MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  WindSpeed3pm  \\\n0  13.398438  22.906250  0.600098           44.0          20.0          24.0   \n1   7.398438  25.093750  0.000000           44.0           4.0          22.0   \n2  12.898438  25.703125  0.000000           46.0          19.0          26.0   \n3   9.203125  28.000000  0.000000           24.0          11.0           9.0   \n4  17.500000  32.312500  1.000000           41.0           7.0          20.0   \n5  14.601562  29.703125  0.199951           56.0          19.0          24.0   \n6  14.296875  25.000000  0.000000           50.0          20.0          24.0   \n7   7.699219  26.703125  0.000000           35.0           6.0          17.0   \n8   9.703125  31.906250  0.000000           80.0           7.0          28.0   \n9  13.101562  30.093750  1.400391           28.0          15.0          11.0   \n\n   Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  ...  WindDir3pm_NNW  \\\n0         71.0         22.0       1007.5       1007.0  ...               0   \n1         44.0         25.0       1010.5       1008.0  ...               0   \n2         38.0         30.0       1007.5       1008.5  ...               0   \n3         45.0         16.0       1017.5       1013.0  ...               0   \n4         82.0         33.0       1011.0       1006.0  ...               0   \n5         55.0         23.0       1009.0       1005.5  ...               0   \n6         49.0         19.0       1009.5       1008.0  ...               0   \n7         48.0         19.0       1013.5       1010.0  ...               0   \n8         42.0          9.0       1009.0       1003.5  ...               0   \n9         58.0         27.0       1007.0       1005.5  ...               0   \n\n   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n0              0             0              0               0               0   \n1              0             0              0               0               0   \n2              0             0              0               0               0   \n3              0             0              0               0               0   \n4              1             0              0               0               0   \n5              0             0              0               0               0   \n6              0             0              0               0               0   \n7              0             0              0               0               0   \n8              1             0              0               0               0   \n9              0             0              0               1               0   \n\n   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n0              0             0               1               0  \n1              0             0               0               1  \n2              0             0               0               1  \n3              0             0               0               0  \n4              0             0               0               0  \n5              0             1               0               0  \n6              0             1               0               0  \n7              0             1               0               0  \n8              0             0               0               0  \n9              0             0               0               0  \n\n[10 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>...</th>\n      <th>WindDir3pm_NNW</th>\n      <th>WindDir3pm_NW</th>\n      <th>WindDir3pm_S</th>\n      <th>WindDir3pm_SE</th>\n      <th>WindDir3pm_SSE</th>\n      <th>WindDir3pm_SSW</th>\n      <th>WindDir3pm_SW</th>\n      <th>WindDir3pm_W</th>\n      <th>WindDir3pm_WNW</th>\n      <th>WindDir3pm_WSW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.398438</td>\n      <td>22.906250</td>\n      <td>0.600098</td>\n      <td>44.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.5</td>\n      <td>1007.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.398438</td>\n      <td>25.093750</td>\n      <td>0.000000</td>\n      <td>44.0</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.5</td>\n      <td>1008.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.898438</td>\n      <td>25.703125</td>\n      <td>0.000000</td>\n      <td>46.0</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.5</td>\n      <td>1008.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.203125</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>24.0</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.5</td>\n      <td>1013.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.500000</td>\n      <td>32.312500</td>\n      <td>1.000000</td>\n      <td>41.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1011.0</td>\n      <td>1006.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.601562</td>\n      <td>29.703125</td>\n      <td>0.199951</td>\n      <td>56.0</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.0</td>\n      <td>1005.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.296875</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>50.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.5</td>\n      <td>1008.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.699219</td>\n      <td>26.703125</td>\n      <td>0.000000</td>\n      <td>35.0</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.5</td>\n      <td>1010.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.703125</td>\n      <td>31.906250</td>\n      <td>0.000000</td>\n      <td>80.0</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1009.0</td>\n      <td>1003.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.101562</td>\n      <td>30.093750</td>\n      <td>1.400391</td>\n      <td>28.0</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.5</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 65 columns</p>\n</div>"},"metadata":{}}],"execution_count":114},{"cell_type":"markdown","source":"## Training and testing: LogReg model (and with cross-validation)\n\nHere we train a standard Logistic Regression model and a LogReg with Cross Validation included in it against the training data. I then evaluate these models against the testing set. Our models did not perform significantly better than those seen in the Existing Work; further discussion on these results are present in later cells.\n\nWe dropped each of the three columns for the X data for these reasons:\n- RainToday: this is the y-feature and should not be in X for any reason.\n- Rainfall: including this would make the learning process trivial, as we unintentionally discovered earlier in this project.\n- RainTomorrow: rather irrelevant to the work at hand; we are looking to learn today's rain, not tomorrow's.","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\n\nX = df_onehot.drop(columns=[\"RainToday\", \"RainTomorrow\", \"Rainfall\"]) # Rainfall is too direct a correlation with RainToday\ny = df_onehot[\"RainToday\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:55.416937Z","iopub.execute_input":"2025-04-30T05:47:55.417238Z","iopub.status.idle":"2025-04-30T05:47:55.644135Z","shell.execute_reply.started":"2025-04-30T05:47:55.417217Z","shell.execute_reply":"2025-04-30T05:47:55.643359Z"}},"outputs":[],"execution_count":115},{"cell_type":"code","source":"logreg = LogisticRegression(random_state=42)\nlogreg.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:47:58.679177Z","iopub.execute_input":"2025-04-30T05:47:58.679441Z","iopub.status.idle":"2025-04-30T05:47:59.584111Z","shell.execute_reply.started":"2025-04-30T05:47:58.679424Z","shell.execute_reply":"2025-04-30T05:47:59.582276Z"}},"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"LogisticRegression(random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":116},{"cell_type":"code","source":"y_pred_test = logreg.predict(X_test)\ny_pred_train = logreg.predict(X_train)\n\nfrom sklearn.metrics import accuracy_score\n\n# Check accuracy against both train and test, see if there is a major difference\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T05:48:35.653270Z","iopub.execute_input":"2025-04-30T05:48:35.653546Z","iopub.status.idle":"2025-04-30T05:48:35.680644Z","shell.execute_reply.started":"2025-04-30T05:48:35.653528Z","shell.execute_reply":"2025-04-30T05:48:35.679679Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8329\nModel accuracy score (against training set): 0.8358\n","output_type":"stream"}],"execution_count":117},{"cell_type":"code","source":"# logreg with built-in 5-fold cross validation. Default penalty is L2.\n# Increased max_iter because the default of 100 wasn't enough to converge.\nlogregcv = LogisticRegressionCV(max_iter=256, cv=5, random_state=42)\nlogregcv.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:29:43.359667Z","iopub.execute_input":"2025-04-29T01:29:43.359985Z","iopub.status.idle":"2025-04-29T01:29:59.604553Z","shell.execute_reply.started":"2025-04-29T01:29:43.359963Z","shell.execute_reply":"2025-04-29T01:29:59.602880Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"LogisticRegressionCV(cv=5, max_iter=256, random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(cv=5, max_iter=256, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(cv=5, max_iter=256, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"y_pred_test = logregcv.predict(X_test)\ny_pred_train = logregcv.predict(X_train)\n\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:30:41.958119Z","iopub.execute_input":"2025-04-29T01:30:41.958395Z","iopub.status.idle":"2025-04-29T01:30:41.986904Z","shell.execute_reply.started":"2025-04-29T01:30:41.958376Z","shell.execute_reply":"2025-04-29T01:30:41.985971Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8333\nModel accuracy score (against training set): 0.8356\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"sum(abs(y_pred_test-y_test)), len(y_test) # visually confirming that the predictions and y_test do add up\n# 3791 misses out of 22736 tests; 0.167 of all predictions are misses. Slightly worse off than the Existing Work results.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:05:01.286672Z","iopub.execute_input":"2025-04-28T17:05:01.287027Z","iopub.status.idle":"2025-04-28T17:05:01.295486Z","shell.execute_reply.started":"2025-04-28T17:05:01.287004Z","shell.execute_reply":"2025-04-28T17:05:01.294747Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(3791, 22736)"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"The LogReg models, with or without cross-validation, achieved around 83% accuracy.\n\nThe performance displayed here is slightly worse than what the models from Existing Work 1 demonstrated (which were trained against RainTomorrow). There are many possible reasons why our model did not achieve greater results; We will explore some of these possible reasons below.","metadata":{}},{"cell_type":"markdown","source":"## LogReg comparisons: different input data\n\nThe data set prepared above is different from the one the Existing Work arrived at. How much will various different data preparation steps affect the model's final performance? We will perform a few tests using \"alternate\" data sets (with some of the different changes applied).\n\n## Alternate Data: Partial fillna()\n\nThe first Alternate data set involves a partial replacement of missing values: We still drop the four columns with 50k-60k missing data, but for all remainder columns we replace missing values with the median value (or, for the wind direction categorical variables, most common entry). This is mostly in line with what the author of the first Existing Work did, minus the four dropped columns.","metadata":{}},{"cell_type":"code","source":"# Copied from previous work.\n\ndf_dropped3 = df_dropped[pd.notna(df_dropped[\"RainToday\"])]\ndf_dropped3[\"Date\"] = pd.to_datetime(df_dropped3[\"Date\"])\ndf_dropped3 = df_dropped3.assign( # Replace the date with day, month, year.\n    Year=df_dropped3[\"Date\"].dt.year,\n    Month=df_dropped3[\"Date\"].dt.month,\n    Day=df_dropped3[\"Date\"].dt.day,\n)\ndf_dropped3.drop('Date', axis=1, inplace=True)\n#df_dropped2[['Day', 'Month', 'Year']] = pd.DataFrame(df_dropped2['Date'].dt.day, df_dropped2['Date'].dt.month, df_dropped2['Date'].dt.year)\ndf_dropped3.head(10)\n#df_dropped2['Date'].dt.day\n\nboolean_numbers_dict = {\n    \"No\": 0,\n    \"Yes\": 1,\n    0: 0,\n    1: 1,\n    None: 0 # Not sure if this is wise, but I will go with it for now\n}\nfor column in [\"RainToday\",\"RainTomorrow\"]:\n    df_dropped3[column] = df_dropped3[column].apply(lambda entry: boolean_numbers_dict[entry])\n#df_dropped3\n\n# Point of divergence. Instead of dropping remaining rows with n/a, replace them ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:31:48.238744Z","iopub.execute_input":"2025-04-29T01:31:48.239499Z","iopub.status.idle":"2025-04-29T01:31:48.592523Z","shell.execute_reply.started":"2025-04-29T01:31:48.239469Z","shell.execute_reply":"2025-04-29T01:31:48.591854Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/621222386.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_dropped3[\"Date\"] = pd.to_datetime(df_dropped3[\"Date\"])\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"for col in df_dropped3.columns:\n    if col not in [\"WindDir9am\", \"WindDir3pm\", \"RainToday\", \"RainTomorrow\", \"WindGustDir\"]:\n        if df_dropped3[col].dtype == object:\n            df_dropped3[col] = df_dropped3[col].astype(np.float64)\ndf_dropped3.dtypes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:31:50.014778Z","iopub.execute_input":"2025-04-29T01:31:50.015077Z","iopub.status.idle":"2025-04-29T01:31:50.082881Z","shell.execute_reply.started":"2025-04-29T01:31:50.015058Z","shell.execute_reply":"2025-04-29T01:31:50.081963Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"MinTemp          float64\nMaxTemp          float64\nRainfall         float64\nWindGustDir       object\nWindGustSpeed    float64\nWindDir9am        object\nWindDir3pm        object\nWindSpeed9am     float64\nWindSpeed3pm     float64\nHumidity9am      float64\nHumidity3pm      float64\nPressure9am      float64\nPressure3pm      float64\nTemp9am          float64\nTemp3pm          float64\nRainToday          int64\nRainTomorrow       int64\nYear               int32\nMonth              int32\nDay                int32\ndtype: object"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"numerical = [col for col in df_dropped3.columns if df_dropped3[col].dtypes != 'O'] \nnumerical","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:31:51.279164Z","iopub.execute_input":"2025-04-29T01:31:51.279512Z","iopub.status.idle":"2025-04-29T01:31:51.286526Z","shell.execute_reply.started":"2025-04-29T01:31:51.279490Z","shell.execute_reply":"2025-04-29T01:31:51.285589Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"['MinTemp',\n 'MaxTemp',\n 'Rainfall',\n 'WindGustSpeed',\n 'WindSpeed9am',\n 'WindSpeed3pm',\n 'Humidity9am',\n 'Humidity3pm',\n 'Pressure9am',\n 'Pressure3pm',\n 'Temp9am',\n 'Temp3pm',\n 'RainToday',\n 'RainTomorrow',\n 'Year',\n 'Month',\n 'Day']"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Replace missing numericals with median instead of deleting rows\n\nfor col in numerical:\n    col_median=df_dropped3[col].median()\n    df_dropped3.fillna({col: col_median}, inplace=True) # using this specific syntax to avoid Pandas warning messages\n\ndf_dropped3.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:31:52.426913Z","iopub.execute_input":"2025-04-29T01:31:52.427348Z","iopub.status.idle":"2025-04-29T01:31:52.520314Z","shell.execute_reply.started":"2025-04-29T01:31:52.427319Z","shell.execute_reply":"2025-04-29T01:31:52.519420Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"MinTemp             0\nMaxTemp             0\nRainfall            0\nWindGustDir      9725\nWindGustSpeed       0\nWindDir9am       9789\nWindDir3pm       3799\nWindSpeed9am        0\nWindSpeed3pm        0\nHumidity9am         0\nHumidity3pm         0\nPressure9am         0\nPressure3pm         0\nTemp9am             0\nTemp3pm             0\nRainToday           0\nRainTomorrow        0\nYear                0\nMonth               0\nDay                 0\ndtype: int64"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"categorical = [col for col in df_dropped3.columns if df_dropped3[col].dtypes == 'O'] \ncategorical # [ WindGustDir, WindDir9am, WindDir3pm ]\nfor cat in categorical:\n    df_dropped3.fillna({cat: df_dropped3[cat].mode()[0]}, inplace=True)\ndf_dropped3.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:31:53.861837Z","iopub.execute_input":"2025-04-29T01:31:53.862167Z","iopub.status.idle":"2025-04-29T01:31:53.962938Z","shell.execute_reply.started":"2025-04-29T01:31:53.862145Z","shell.execute_reply":"2025-04-29T01:31:53.962263Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"MinTemp          0\nMaxTemp          0\nRainfall         0\nWindGustDir      0\nWindGustSpeed    0\nWindDir9am       0\nWindDir3pm       0\nWindSpeed9am     0\nWindSpeed3pm     0\nHumidity9am      0\nHumidity3pm      0\nPressure9am      0\nPressure3pm      0\nTemp9am          0\nTemp3pm          0\nRainToday        0\nRainTomorrow     0\nYear             0\nMonth            0\nDay              0\ndtype: int64"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"df_onehot2 = df_dropped3\nfor categorical in [\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]:\n    df_onehot2 = pd.concat([df_onehot2, pd.get_dummies(df_onehot2[categorical], prefix=categorical)], axis=1)\n    df_onehot2.drop(columns=categorical, inplace=True)\ndf_onehot2.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:31:55.047676Z","iopub.execute_input":"2025-04-29T01:31:55.047968Z","iopub.status.idle":"2025-04-29T01:31:55.186691Z","shell.execute_reply.started":"2025-04-29T01:31:55.047948Z","shell.execute_reply":"2025-04-29T01:31:55.185932Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"   MinTemp  MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  WindSpeed3pm  \\\n0     13.4     22.9       0.6           44.0          20.0          24.0   \n1      7.4     25.1       0.0           44.0           4.0          22.0   \n2     12.9     25.7       0.0           46.0          19.0          26.0   \n3      9.2     28.0       0.0           24.0          11.0           9.0   \n4     17.5     32.3       1.0           41.0           7.0          20.0   \n5     14.6     29.7       0.2           56.0          19.0          24.0   \n6     14.3     25.0       0.0           50.0          20.0          24.0   \n7      7.7     26.7       0.0           35.0           6.0          17.0   \n8      9.7     31.9       0.0           80.0           7.0          28.0   \n9     13.1     30.1       1.4           28.0          15.0          11.0   \n\n   Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  ...  WindDir3pm_NNW  \\\n0         71.0         22.0       1007.7       1007.1  ...           False   \n1         44.0         25.0       1010.6       1007.8  ...           False   \n2         38.0         30.0       1007.6       1008.7  ...           False   \n3         45.0         16.0       1017.6       1012.8  ...           False   \n4         82.0         33.0       1010.8       1006.0  ...           False   \n5         55.0         23.0       1009.2       1005.4  ...           False   \n6         49.0         19.0       1009.6       1008.2  ...           False   \n7         48.0         19.0       1013.4       1010.1  ...           False   \n8         42.0          9.0       1008.9       1003.6  ...           False   \n9         58.0         27.0       1007.0       1005.7  ...           False   \n\n   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n0          False         False          False           False           False   \n1          False         False          False           False           False   \n2          False         False          False           False           False   \n3          False         False          False           False           False   \n4           True         False          False           False           False   \n5          False         False          False           False           False   \n6          False         False          False           False           False   \n7          False         False          False           False           False   \n8           True         False          False           False           False   \n9          False         False          False            True           False   \n\n   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n0          False         False            True           False  \n1          False         False           False            True  \n2          False         False           False            True  \n3          False         False           False           False  \n4          False         False           False           False  \n5          False          True           False           False  \n6          False          True           False           False  \n7          False          True           False           False  \n8          False         False           False           False  \n9          False         False           False           False  \n\n[10 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>...</th>\n      <th>WindDir3pm_NNW</th>\n      <th>WindDir3pm_NW</th>\n      <th>WindDir3pm_S</th>\n      <th>WindDir3pm_SE</th>\n      <th>WindDir3pm_SSE</th>\n      <th>WindDir3pm_SSW</th>\n      <th>WindDir3pm_SW</th>\n      <th>WindDir3pm_W</th>\n      <th>WindDir3pm_WNW</th>\n      <th>WindDir3pm_WSW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.4</td>\n      <td>22.9</td>\n      <td>0.6</td>\n      <td>44.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.7</td>\n      <td>1007.1</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.4</td>\n      <td>25.1</td>\n      <td>0.0</td>\n      <td>44.0</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.6</td>\n      <td>1007.8</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.9</td>\n      <td>25.7</td>\n      <td>0.0</td>\n      <td>46.0</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.6</td>\n      <td>1008.7</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.2</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.6</td>\n      <td>1012.8</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.5</td>\n      <td>32.3</td>\n      <td>1.0</td>\n      <td>41.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1010.8</td>\n      <td>1006.0</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.6</td>\n      <td>29.7</td>\n      <td>0.2</td>\n      <td>56.0</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.2</td>\n      <td>1005.4</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.3</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.6</td>\n      <td>1008.2</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.7</td>\n      <td>26.7</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.4</td>\n      <td>1010.1</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.7</td>\n      <td>31.9</td>\n      <td>0.0</td>\n      <td>80.0</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1008.9</td>\n      <td>1003.6</td>\n      <td>...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.1</td>\n      <td>30.1</td>\n      <td>1.4</td>\n      <td>28.0</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.7</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 65 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"for col in df_onehot2.columns:\n    if df_onehot2[col].dtype == bool:\n        df_onehot2[col] = df_onehot2[col].astype(np.int8)\n# Convert bool to integer 0/1; not doing so causes NaN values to appear in the train-test-s-lot partitions\ndf_onehot2.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:31:56.771652Z","iopub.execute_input":"2025-04-29T01:31:56.771968Z","iopub.status.idle":"2025-04-29T01:31:56.811349Z","shell.execute_reply.started":"2025-04-29T01:31:56.771947Z","shell.execute_reply":"2025-04-29T01:31:56.810385Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   MinTemp  MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  WindSpeed3pm  \\\n0     13.4     22.9       0.6           44.0          20.0          24.0   \n1      7.4     25.1       0.0           44.0           4.0          22.0   \n2     12.9     25.7       0.0           46.0          19.0          26.0   \n3      9.2     28.0       0.0           24.0          11.0           9.0   \n4     17.5     32.3       1.0           41.0           7.0          20.0   \n5     14.6     29.7       0.2           56.0          19.0          24.0   \n6     14.3     25.0       0.0           50.0          20.0          24.0   \n7      7.7     26.7       0.0           35.0           6.0          17.0   \n8      9.7     31.9       0.0           80.0           7.0          28.0   \n9     13.1     30.1       1.4           28.0          15.0          11.0   \n\n   Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  ...  WindDir3pm_NNW  \\\n0         71.0         22.0       1007.7       1007.1  ...               0   \n1         44.0         25.0       1010.6       1007.8  ...               0   \n2         38.0         30.0       1007.6       1008.7  ...               0   \n3         45.0         16.0       1017.6       1012.8  ...               0   \n4         82.0         33.0       1010.8       1006.0  ...               0   \n5         55.0         23.0       1009.2       1005.4  ...               0   \n6         49.0         19.0       1009.6       1008.2  ...               0   \n7         48.0         19.0       1013.4       1010.1  ...               0   \n8         42.0          9.0       1008.9       1003.6  ...               0   \n9         58.0         27.0       1007.0       1005.7  ...               0   \n\n   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n0              0             0              0               0               0   \n1              0             0              0               0               0   \n2              0             0              0               0               0   \n3              0             0              0               0               0   \n4              1             0              0               0               0   \n5              0             0              0               0               0   \n6              0             0              0               0               0   \n7              0             0              0               0               0   \n8              1             0              0               0               0   \n9              0             0              0               1               0   \n\n   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n0              0             0               1               0  \n1              0             0               0               1  \n2              0             0               0               1  \n3              0             0               0               0  \n4              0             0               0               0  \n5              0             1               0               0  \n6              0             1               0               0  \n7              0             1               0               0  \n8              0             0               0               0  \n9              0             0               0               0  \n\n[10 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>Pressure9am</th>\n      <th>Pressure3pm</th>\n      <th>...</th>\n      <th>WindDir3pm_NNW</th>\n      <th>WindDir3pm_NW</th>\n      <th>WindDir3pm_S</th>\n      <th>WindDir3pm_SE</th>\n      <th>WindDir3pm_SSE</th>\n      <th>WindDir3pm_SSW</th>\n      <th>WindDir3pm_SW</th>\n      <th>WindDir3pm_W</th>\n      <th>WindDir3pm_WNW</th>\n      <th>WindDir3pm_WSW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.4</td>\n      <td>22.9</td>\n      <td>0.6</td>\n      <td>44.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>1007.7</td>\n      <td>1007.1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.4</td>\n      <td>25.1</td>\n      <td>0.0</td>\n      <td>44.0</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>1010.6</td>\n      <td>1007.8</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.9</td>\n      <td>25.7</td>\n      <td>0.0</td>\n      <td>46.0</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>1007.6</td>\n      <td>1008.7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.2</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>24.0</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>1017.6</td>\n      <td>1012.8</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.5</td>\n      <td>32.3</td>\n      <td>1.0</td>\n      <td>41.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>1010.8</td>\n      <td>1006.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.6</td>\n      <td>29.7</td>\n      <td>0.2</td>\n      <td>56.0</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>1009.2</td>\n      <td>1005.4</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.3</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>50.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1009.6</td>\n      <td>1008.2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.7</td>\n      <td>26.7</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>1013.4</td>\n      <td>1010.1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.7</td>\n      <td>31.9</td>\n      <td>0.0</td>\n      <td>80.0</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>1008.9</td>\n      <td>1003.6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.1</td>\n      <td>30.1</td>\n      <td>1.4</td>\n      <td>28.0</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>1007.0</td>\n      <td>1005.7</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 65 columns</p>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split\n\nscaler = StandardScaler()\n\nX = df_onehot2.drop(columns=[\"RainToday\", \"RainTomorrow\", \"Rainfall\"])\ny = df_onehot2[\"RainToday\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:07:34.779227Z","iopub.execute_input":"2025-04-28T17:07:34.779532Z","iopub.status.idle":"2025-04-28T17:07:35.041376Z","shell.execute_reply.started":"2025-04-28T17:07:34.779511Z","shell.execute_reply":"2025-04-28T17:07:35.040614Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"logreg = LogisticRegression(random_state=42)\nlogreg.fit(X_train, y_train)\n\ny_pred_test = logreg.predict(X_test)\ny_pred_train = logreg.predict(X_train)\n\nfrom sklearn.metrics import accuracy_score\n\n# Check accuracy against both train and test, see if there is a major difference\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:07:37.772238Z","iopub.execute_input":"2025-04-28T17:07:37.772537Z","iopub.status.idle":"2025-04-28T17:07:38.774463Z","shell.execute_reply.started":"2025-04-28T17:07:37.772516Z","shell.execute_reply":"2025-04-28T17:07:38.773765Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8311\nModel accuracy score (against training set): 0.8304\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# logreg with built-in 5-fold cross validation. Default penalty is L2.\n# Increased max_iter because the default of 100 wasn't enough to converge.\nlogregcv = LogisticRegressionCV(max_iter=256, cv=5, random_state=42)\nlogregcv.fit(X_train, y_train)\n\ny_pred_test = logregcv.predict(X_test)\ny_pred_train = logregcv.predict(X_train)\n\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:07:39.768984Z","iopub.execute_input":"2025-04-28T17:07:39.769284Z","iopub.status.idle":"2025-04-28T17:07:54.795650Z","shell.execute_reply.started":"2025-04-28T17:07:39.769264Z","shell.execute_reply":"2025-04-28T17:07:54.794479Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8310\nModel accuracy score (against training set): 0.8304\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# visually confirming that the predictions and y_test do add up\n# This is for the base LogReg, not LogRegCV.\nsum(abs(y_pred_test - y_test)), len(y_test)\n# Comparable to first attempt results.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:08:05.586266Z","iopub.execute_input":"2025-04-28T17:08:05.586553Z","iopub.status.idle":"2025-04-28T17:08:05.596155Z","shell.execute_reply.started":"2025-04-28T17:08:05.586534Z","shell.execute_reply":"2025-04-28T17:08:05.595326Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(4805, 28440)"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"The partially imputed data achieved comparable performances when used to train logistic regression models with the same hyperparameters. Imputing instead of discarding these numerical features did not have as great of an effect in either the positive or the negative direction than expected.","metadata":{}},{"cell_type":"markdown","source":"## Alternate Data Set: \"Original\"\n\nThe second alternate data set will be largely similar the one used in the first Existing Work. We will keep all columns and fillna() all of them. The only difference is that, while in the Existing Work the dev did a train_test_split first (and used X_train medians and modes to impute for both), we imputed the medians and modes based on the full data set before train_test_split.","metadata":{}},{"cell_type":"code","source":"df_full = df \ndf_full[\"Date\"] = pd.to_datetime(df_full[\"Date\"])\ndf_full = df_full.assign( # Replace the date with day, month, year.\n    Year=df_full[\"Date\"].dt.year,\n    Month=df_full[\"Date\"].dt.month,\n    Day=df_full[\"Date\"].dt.day,\n)\ndf_full.drop('Date', axis=1, inplace=True)\n\ndf_full.head(10)\n\n\nboolean_numbers_dict = {\n    \"No\": 0,\n    \"Yes\": 1,\n    0: 0,\n    1: 1,\n    None: 0 # Not sure if this is wise, but I will go with it for now\n}\nfor column in [\"RainToday\",\"RainTomorrow\"]:\n    df_full[column] = df_full[column].apply(lambda entry: boolean_numbers_dict[entry])\n\n# fillna() all rowas.\n\nfor col in df_full.columns:\n    if col not in [\"WindDir9am\", \"WindDir3pm\", \"RainToday\", \"RainTomorrow\", \"WindGustDir\", \"Location\"]:\n        if df_full[col].dtype == object:\n            df_full[col] = df_full[col].astype(np.float64)\n\nnumerical = [col for col in df_full.columns if df_full[col].dtypes != 'O'] \nfor col in numerical:\n    col_median=df_full[col].median()\n    df_full.fillna({col: col_median}, inplace=True) # using this specific syntax to avoid Pandas warning messages\n\ncategorical = [col for col in df_full.columns if df_full[col].dtypes == 'O'] \ncategorical # [ WindGustDir, WindDir9am, WindDir3pm ]\nfor cat in categorical:\n    df_full.fillna({cat: df_full[cat].mode()[0]}, inplace=True)\n\ndf_full.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:32:01.867179Z","iopub.execute_input":"2025-04-29T01:32:01.867493Z","iopub.status.idle":"2025-04-29T01:32:02.519198Z","shell.execute_reply.started":"2025-04-29T01:32:01.867461Z","shell.execute_reply":"2025-04-29T01:32:02.518380Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Location         0\nMinTemp          0\nMaxTemp          0\nRainfall         0\nEvaporation      0\nSunshine         0\nWindGustDir      0\nWindGustSpeed    0\nWindDir9am       0\nWindDir3pm       0\nWindSpeed9am     0\nWindSpeed3pm     0\nHumidity9am      0\nHumidity3pm      0\nPressure9am      0\nPressure3pm      0\nCloud9am         0\nCloud3pm         0\nTemp9am          0\nTemp3pm          0\nRainToday        0\nRainTomorrow     0\nYear             0\nMonth            0\nDay              0\ndtype: int64"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"df_onehot_full = df_full\nfor categorical in [\"WindDir9am\", \"WindDir3pm\", \"WindGustDir\", \"Location\"]:\n    df_onehot_full = pd.concat([df_onehot_full, pd.get_dummies(df_onehot_full[categorical], prefix=categorical)], axis=1)\n    df_onehot_full.drop(columns=categorical, inplace=True)\nfor col in df_onehot_full.columns:\n    if df_onehot_full[col].dtype == bool:\n        df_onehot_full[col] = df_onehot_full[col].astype(np.int8)\n# Convert bool to integer 0/1; not doing so causes NaN values to appear in the train-test-s-lot partitions\ndf_onehot_full.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:32:04.411756Z","iopub.execute_input":"2025-04-29T01:32:04.412104Z","iopub.status.idle":"2025-04-29T01:32:04.634551Z","shell.execute_reply.started":"2025-04-29T01:32:04.412031Z","shell.execute_reply":"2025-04-29T01:32:04.633833Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n0     13.4     22.9       0.6          4.8       8.4           44.0   \n1      7.4     25.1       0.0          4.8       8.4           44.0   \n2     12.9     25.7       0.0          4.8       8.4           46.0   \n3      9.2     28.0       0.0          4.8       8.4           24.0   \n4     17.5     32.3       1.0          4.8       8.4           41.0   \n5     14.6     29.7       0.2          4.8       8.4           56.0   \n6     14.3     25.0       0.0          4.8       8.4           50.0   \n7      7.7     26.7       0.0          4.8       8.4           35.0   \n8      9.7     31.9       0.0          4.8       8.4           80.0   \n9     13.1     30.1       1.4          4.8       8.4           28.0   \n\n   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n0          20.0          24.0         71.0         22.0  ...   \n1           4.0          22.0         44.0         25.0  ...   \n2          19.0          26.0         38.0         30.0  ...   \n3          11.0           9.0         45.0         16.0  ...   \n4           7.0          20.0         82.0         33.0  ...   \n5          19.0          24.0         55.0         23.0  ...   \n6          20.0          24.0         49.0         19.0  ...   \n7           6.0          17.0         48.0         19.0  ...   \n8           7.0          28.0         42.0          9.0  ...   \n9          15.0          11.0         58.0         27.0  ...   \n\n   Location_Townsville  Location_Tuggeranong  Location_Uluru  \\\n0                    0                     0               0   \n1                    0                     0               0   \n2                    0                     0               0   \n3                    0                     0               0   \n4                    0                     0               0   \n5                    0                     0               0   \n6                    0                     0               0   \n7                    0                     0               0   \n8                    0                     0               0   \n9                    0                     0               0   \n\n   Location_WaggaWagga  Location_Walpole  Location_Watsonia  \\\n0                    0                 0                  0   \n1                    0                 0                  0   \n2                    0                 0                  0   \n3                    0                 0                  0   \n4                    0                 0                  0   \n5                    0                 0                  0   \n6                    0                 0                  0   \n7                    0                 0                  0   \n8                    0                 0                  0   \n9                    0                 0                  0   \n\n   Location_Williamtown  Location_Witchcliffe  Location_Wollongong  \\\n0                     0                     0                    0   \n1                     0                     0                    0   \n2                     0                     0                    0   \n3                     0                     0                    0   \n4                     0                     0                    0   \n5                     0                     0                    0   \n6                     0                     0                    0   \n7                     0                     0                    0   \n8                     0                     0                    0   \n9                     0                     0                    0   \n\n   Location_Woomera  \n0                 0  \n1                 0  \n2                 0  \n3                 0  \n4                 0  \n5                 0  \n6                 0  \n7                 0  \n8                 0  \n9                 0  \n\n[10 rows x 118 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>...</th>\n      <th>Location_Townsville</th>\n      <th>Location_Tuggeranong</th>\n      <th>Location_Uluru</th>\n      <th>Location_WaggaWagga</th>\n      <th>Location_Walpole</th>\n      <th>Location_Watsonia</th>\n      <th>Location_Williamtown</th>\n      <th>Location_Witchcliffe</th>\n      <th>Location_Wollongong</th>\n      <th>Location_Woomera</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13.4</td>\n      <td>22.9</td>\n      <td>0.6</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>44.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>71.0</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.4</td>\n      <td>25.1</td>\n      <td>0.0</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>44.0</td>\n      <td>4.0</td>\n      <td>22.0</td>\n      <td>44.0</td>\n      <td>25.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12.9</td>\n      <td>25.7</td>\n      <td>0.0</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>46.0</td>\n      <td>19.0</td>\n      <td>26.0</td>\n      <td>38.0</td>\n      <td>30.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.2</td>\n      <td>28.0</td>\n      <td>0.0</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>24.0</td>\n      <td>11.0</td>\n      <td>9.0</td>\n      <td>45.0</td>\n      <td>16.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.5</td>\n      <td>32.3</td>\n      <td>1.0</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>41.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>82.0</td>\n      <td>33.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>14.6</td>\n      <td>29.7</td>\n      <td>0.2</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>56.0</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>55.0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>14.3</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>50.0</td>\n      <td>20.0</td>\n      <td>24.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.7</td>\n      <td>26.7</td>\n      <td>0.0</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>35.0</td>\n      <td>6.0</td>\n      <td>17.0</td>\n      <td>48.0</td>\n      <td>19.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9.7</td>\n      <td>31.9</td>\n      <td>0.0</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>80.0</td>\n      <td>7.0</td>\n      <td>28.0</td>\n      <td>42.0</td>\n      <td>9.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>13.1</td>\n      <td>30.1</td>\n      <td>1.4</td>\n      <td>4.8</td>\n      <td>8.4</td>\n      <td>28.0</td>\n      <td>15.0</td>\n      <td>11.0</td>\n      <td>58.0</td>\n      <td>27.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 118 columns</p>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"df_onehot_full.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:32:05.657619Z","iopub.execute_input":"2025-04-29T01:32:05.657923Z","iopub.status.idle":"2025-04-29T01:32:05.663801Z","shell.execute_reply.started":"2025-04-29T01:32:05.657901Z","shell.execute_reply":"2025-04-29T01:32:05.663116Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"Index(['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n       'Humidity3pm',\n       ...\n       'Location_Townsville', 'Location_Tuggeranong', 'Location_Uluru',\n       'Location_WaggaWagga', 'Location_Walpole', 'Location_Watsonia',\n       'Location_Williamtown', 'Location_Witchcliffe', 'Location_Wollongong',\n       'Location_Woomera'],\n      dtype='object', length=118)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"df_onehot_full.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:32:06.860962Z","iopub.execute_input":"2025-04-29T01:32:06.861847Z","iopub.status.idle":"2025-04-29T01:32:07.458712Z","shell.execute_reply.started":"2025-04-29T01:32:06.861811Z","shell.execute_reply":"2025-04-29T01:32:07.457968Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"             MinTemp        MaxTemp       Rainfall    Evaporation  \\\ncount  145460.000000  145460.000000  145460.000000  145460.000000   \nmean       12.192053      23.215962       2.307990       5.179779   \nstd         6.365780       7.088358       8.389771       3.178819   \nmin        -8.500000      -4.800000       0.000000       0.000000   \n25%         7.700000      18.000000       0.000000       4.000000   \n50%        12.000000      22.600000       0.000000       4.800000   \n75%        16.800000      28.200000       0.600000       5.200000   \nmax        33.900000      48.100000     371.000000     145.000000   \n\n            Sunshine  WindGustSpeed   WindSpeed9am   WindSpeed3pm  \\\ncount  145460.000000  145460.000000  145460.000000  145460.000000   \nmean        7.989889      39.962189      14.030751      18.669758   \nstd         2.757790      13.120931       8.861796       8.716716   \nmin         0.000000       6.000000       0.000000       0.000000   \n25%         8.200000      31.000000       7.000000      13.000000   \n50%         8.400000      39.000000      13.000000      19.000000   \n75%         8.700000      46.000000      19.000000      24.000000   \nmax        14.500000     135.000000     130.000000      87.000000   \n\n         Humidity9am    Humidity3pm  ...  Location_Townsville  \\\ncount  145460.000000  145460.000000  ...        145460.000000   \nmean       68.901251      51.553396  ...             0.020899   \nstd        18.855360      20.471345  ...             0.143047   \nmin         0.000000       0.000000  ...             0.000000   \n25%        57.000000      37.000000  ...             0.000000   \n50%        70.000000      52.000000  ...             0.000000   \n75%        83.000000      65.000000  ...             0.000000   \nmax       100.000000     100.000000  ...             1.000000   \n\n       Location_Tuggeranong  Location_Uluru  Location_WaggaWagga  \\\ncount         145460.000000   145460.000000        145460.000000   \nmean               0.020892        0.010848             0.020686   \nstd                0.143024        0.103589             0.142332   \nmin                0.000000        0.000000             0.000000   \n25%                0.000000        0.000000             0.000000   \n50%                0.000000        0.000000             0.000000   \n75%                0.000000        0.000000             0.000000   \nmax                1.000000        1.000000             1.000000   \n\n       Location_Walpole  Location_Watsonia  Location_Williamtown  \\\ncount     145460.000000      145460.000000         145460.000000   \nmean           0.020665           0.020686              0.020686   \nstd            0.142262           0.142332              0.142332   \nmin            0.000000           0.000000              0.000000   \n25%            0.000000           0.000000              0.000000   \n50%            0.000000           0.000000              0.000000   \n75%            0.000000           0.000000              0.000000   \nmax            1.000000           1.000000              1.000000   \n\n       Location_Witchcliffe  Location_Wollongong  Location_Woomera  \ncount         145460.000000        145460.000000     145460.000000  \nmean               0.020686             0.020899          0.020686  \nstd                0.142332             0.143047          0.142332  \nmin                0.000000             0.000000          0.000000  \n25%                0.000000             0.000000          0.000000  \n50%                0.000000             0.000000          0.000000  \n75%                0.000000             0.000000          0.000000  \nmax                1.000000             1.000000          1.000000  \n\n[8 rows x 118 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>...</th>\n      <th>Location_Townsville</th>\n      <th>Location_Tuggeranong</th>\n      <th>Location_Uluru</th>\n      <th>Location_WaggaWagga</th>\n      <th>Location_Walpole</th>\n      <th>Location_Watsonia</th>\n      <th>Location_Williamtown</th>\n      <th>Location_Witchcliffe</th>\n      <th>Location_Wollongong</th>\n      <th>Location_Woomera</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>...</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n      <td>145460.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>12.192053</td>\n      <td>23.215962</td>\n      <td>2.307990</td>\n      <td>5.179779</td>\n      <td>7.989889</td>\n      <td>39.962189</td>\n      <td>14.030751</td>\n      <td>18.669758</td>\n      <td>68.901251</td>\n      <td>51.553396</td>\n      <td>...</td>\n      <td>0.020899</td>\n      <td>0.020892</td>\n      <td>0.010848</td>\n      <td>0.020686</td>\n      <td>0.020665</td>\n      <td>0.020686</td>\n      <td>0.020686</td>\n      <td>0.020686</td>\n      <td>0.020899</td>\n      <td>0.020686</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>6.365780</td>\n      <td>7.088358</td>\n      <td>8.389771</td>\n      <td>3.178819</td>\n      <td>2.757790</td>\n      <td>13.120931</td>\n      <td>8.861796</td>\n      <td>8.716716</td>\n      <td>18.855360</td>\n      <td>20.471345</td>\n      <td>...</td>\n      <td>0.143047</td>\n      <td>0.143024</td>\n      <td>0.103589</td>\n      <td>0.142332</td>\n      <td>0.142262</td>\n      <td>0.142332</td>\n      <td>0.142332</td>\n      <td>0.142332</td>\n      <td>0.143047</td>\n      <td>0.142332</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-8.500000</td>\n      <td>-4.800000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7.700000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>8.200000</td>\n      <td>31.000000</td>\n      <td>7.000000</td>\n      <td>13.000000</td>\n      <td>57.000000</td>\n      <td>37.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>12.000000</td>\n      <td>22.600000</td>\n      <td>0.000000</td>\n      <td>4.800000</td>\n      <td>8.400000</td>\n      <td>39.000000</td>\n      <td>13.000000</td>\n      <td>19.000000</td>\n      <td>70.000000</td>\n      <td>52.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>16.800000</td>\n      <td>28.200000</td>\n      <td>0.600000</td>\n      <td>5.200000</td>\n      <td>8.700000</td>\n      <td>46.000000</td>\n      <td>19.000000</td>\n      <td>24.000000</td>\n      <td>83.000000</td>\n      <td>65.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>33.900000</td>\n      <td>48.100000</td>\n      <td>371.000000</td>\n      <td>145.000000</td>\n      <td>14.500000</td>\n      <td>135.000000</td>\n      <td>130.000000</td>\n      <td>87.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 118 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split\n\nscaler = StandardScaler()\n\nX = df_onehot_full.drop(columns=[\"RainToday\", \"RainTomorrow\", \"Rainfall\"])\ny = df_onehot_full[\"RainToday\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:09:08.187359Z","iopub.execute_input":"2025-04-28T17:09:08.187665Z","iopub.status.idle":"2025-04-28T17:09:08.712829Z","shell.execute_reply.started":"2025-04-28T17:09:08.187645Z","shell.execute_reply":"2025-04-28T17:09:08.712097Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# logreg with built-in 5-fold cross validation. Default penalty is L2.\n# Increased max_iter because the default of 100 wasn't enough to converge.\nlogregcv = LogisticRegressionCV(max_iter=256, cv=5, random_state=42)\nlogregcv.fit(X_train, y_train)\n\ny_pred_test = logregcv.predict(X_test)\ny_pred_train = logregcv.predict(X_train)\n\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:09:11.402676Z","iopub.execute_input":"2025-04-28T17:09:11.403030Z","iopub.status.idle":"2025-04-28T17:09:38.695555Z","shell.execute_reply.started":"2025-04-28T17:09:11.403007Z","shell.execute_reply":"2025-04-28T17:09:38.694820Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"logreg = LogisticRegression(random_state=42)\nlogreg.fit(X_train, y_train)\n\ny_pred_test = logreg.predict(X_test)\ny_pred_train = logreg.predict(X_train)\n\nfrom sklearn.metrics import accuracy_score\n\n# Check accuracy against both train and test, see if there is a major difference\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:11:21.189673Z","iopub.execute_input":"2025-04-28T17:11:21.190043Z","iopub.status.idle":"2025-04-28T17:11:22.760363Z","shell.execute_reply.started":"2025-04-28T17:11:21.190020Z","shell.execute_reply":"2025-04-28T17:11:22.759412Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# visually confirming that the predictions and y_test do add up\n# This is for the base LogReg, not LogRegCV.\nsum(abs(y_pred_test - y_test)), len(y_test)\n# Slightly better performance than before, but still in the same ballpark.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:11:30.267944Z","iopub.execute_input":"2025-04-28T17:11:30.268218Z","iopub.status.idle":"2025-04-28T17:11:30.277162Z","shell.execute_reply.started":"2025-04-28T17:11:30.268201Z","shell.execute_reply":"2025-04-28T17:11:30.276272Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"(4528, 29092)"},"metadata":{}}],"execution_count":46},{"cell_type":"markdown","source":"At the beginning of the project, member Jason Wu hypothesized that imputing upwards of 65,000 missing data entries in some of the features may have contributed to the Existing Work model's performance cap of around 0.85 accuracy. This contributed to the decision to go with the initial data processing approach of dropping the features with the most missing values and dropping the remaining rows with missing values.\n\nContrary to said initial beliefs, replacing this many missing values did not noticeably hurt the model's performance - if anything, it improved its performance a little.\n\n## Observations and Additional Tests: solver\n\nDuring a re-review of Existing Material 1 Jason noticed that their LogReg model used a solver hyperparam of \"liblinear\" instead of the default \"lbfgs\". It may be wise to test out the effects of each solver.\n\nWe  should have done this through a GridSearchCV alongside other hyperparameters, however as of the writing of this sentence it's a bit too late to be trying that.","metadata":{}},{"cell_type":"code","source":"solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n\nfor solver in solvers:\n    logreg = LogisticRegression(random_state=42, solver=solver)\n    logreg.fit(X_train, y_train)\n    \n    y_pred_test = logreg.predict(X_test)\n    y_pred_train = logreg.predict(X_train)\n    \n    from sklearn.metrics import accuracy_score\n    \n    # Check accuracy against both train and test, see if there is a major difference\n    print(f\"Model using solver {solver}\")\n    print('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n    print('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:12:30.198508Z","iopub.execute_input":"2025-04-28T17:12:30.198810Z","iopub.status.idle":"2025-04-28T17:12:52.441461Z","shell.execute_reply.started":"2025-04-28T17:12:30.198790Z","shell.execute_reply":"2025-04-28T17:12:52.440320Z"}},"outputs":[{"name":"stdout","text":"Model using solver lbfgs\nModel accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\nModel using solver liblinear\nModel accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\nModel using solver newton-cg\nModel accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\nModel using solver newton-cholesky\nModel accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\nModel using solver sag\nModel accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\nModel using solver saga\nModel accuracy score (against testing set): 0.8444\nModel accuracy score (against training set): 0.8396\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"It seems that the exact solver did not make a noticeable difference. Our thoughts are as follows:\n- Perhaps my decision to impute with whole data set's median and mode for numerical and categorical values led to the model overfitting, by virtue of some information on the testing data points \"leaking\" into the training data points.\n- However, if that was the case, then I should have experienced noticeably worse performance on my initial data set (which did not impute any values but instead only deleted values) rather than the slight drop.\n- If the rows are missing values at random, then removing the rows with missing values should not impact this much. If the rows are missing values in a specific pattern, then the situation is out of my hands - I do not know what this pattern might look like.","metadata":{}},{"cell_type":"markdown","source":"## Alternate Data Set: DROP TABLE;\n\nWe will drop all rows with any missing values. This will result in an extreme reduction in usable rows for training and testing.","metadata":{}},{"cell_type":"code","source":"df_fulldrop = df\ndf_fulldrop.dropna(inplace=True)\ndf_fulldrop[\"Date\"] = pd.to_datetime(df_fulldrop[\"Date\"])\ndf_fulldrop = df_fulldrop.assign( # Replace the date with day, month, year.\n    Year=df_fulldrop[\"Date\"].dt.year,\n    Month=df_fulldrop[\"Date\"].dt.month,\n    Day=df_fulldrop[\"Date\"].dt.day,\n)\ndf_fulldrop.drop('Date', axis=1, inplace=True)\n\ndf_fulldrop.head(10)\n\n\nboolean_numbers_dict = {\n    \"No\": 0,\n    \"Yes\": 1,\n    0: 0,\n    1: 1,\n    None: 0 # Not sure if this is wise, but I will go with it for now\n}\nfor column in [\"RainToday\",\"RainTomorrow\"]:\n    df_fulldrop[column] = df_fulldrop[column].apply(lambda entry: boolean_numbers_dict[entry])\n\n# fillna() all rowas.\n\nfor col in df_fulldrop.columns:\n    if col not in [\"WindDir9am\", \"WindDir3pm\", \"RainToday\", \"RainTomorrow\", \"WindGustDir\", \"Location\"]:\n        if df_fulldrop[col].dtype == object:\n            df_fulldrop[col] = df_fulldrop[col].astype(np.float64)\n\ndf_onehot_fulldrop = df_fulldrop\nfor categorical in [\"WindDir9am\", \"WindDir3pm\", \"WindGustDir\", \"Location\"]:\n    df_onehot_fulldrop = pd.concat([df_onehot_fulldrop, pd.get_dummies(df_onehot_fulldrop[categorical], prefix=categorical)], axis=1)\n    df_onehot_fulldrop.drop(columns=categorical, inplace=True)\nfor col in df_onehot_fulldrop.columns:\n    if df_onehot_fulldrop[col].dtype == bool:\n        df_onehot_fulldrop[col] = df_onehot_fulldrop[col].astype(np.int8)\n# Convert bool to integer 0/1; not doing so causes NaN values to appear in the train-test-s-lot partitions\ndf_onehot_fulldrop.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:53:37.413401Z","iopub.execute_input":"2025-04-29T01:53:37.413802Z","iopub.status.idle":"2025-04-29T01:53:37.790625Z","shell.execute_reply.started":"2025-04-29T01:53:37.413779Z","shell.execute_reply":"2025-04-29T01:53:37.789833Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"      MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n6049     17.9     35.2       0.0         12.0      12.3           48.0   \n6050     18.4     28.9       0.0         14.8      13.0           37.0   \n6052     19.4     37.6       0.0         10.8      10.6           46.0   \n6053     21.9     38.4       0.0         11.4      12.2           31.0   \n6054     24.2     41.0       0.0         11.2       8.4           35.0   \n6055     27.1     36.1       0.0         13.0       0.0           43.0   \n6056     23.3     34.0       0.0          9.8      12.6           41.0   \n6057     16.1     34.2       0.0         14.6      13.2           37.0   \n6058     19.0     35.5       0.0         12.0      12.3           48.0   \n6059     19.7     35.5       0.0         11.0      12.7           41.0   \n\n      WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n6049           6.0          20.0         20.0         13.0  ...   \n6050          19.0          19.0         30.0          8.0  ...   \n6052          30.0          15.0         42.0         22.0  ...   \n6053           6.0           6.0         37.0         22.0  ...   \n6054          17.0          13.0         19.0         15.0  ...   \n6055           7.0          20.0         26.0         19.0  ...   \n6056          17.0          19.0         33.0         15.0  ...   \n6057          15.0           6.0         25.0          9.0  ...   \n6058          30.0           9.0         46.0         28.0  ...   \n6059          15.0          17.0         61.0         14.0  ...   \n\n      Location_PerthAirport  Location_Portland  Location_Sale  \\\n6049                      0                  0              0   \n6050                      0                  0              0   \n6052                      0                  0              0   \n6053                      0                  0              0   \n6054                      0                  0              0   \n6055                      0                  0              0   \n6056                      0                  0              0   \n6057                      0                  0              0   \n6058                      0                  0              0   \n6059                      0                  0              0   \n\n      Location_Sydney  Location_SydneyAirport  Location_Townsville  \\\n6049                0                       0                    0   \n6050                0                       0                    0   \n6052                0                       0                    0   \n6053                0                       0                    0   \n6054                0                       0                    0   \n6055                0                       0                    0   \n6056                0                       0                    0   \n6057                0                       0                    0   \n6058                0                       0                    0   \n6059                0                       0                    0   \n\n      Location_WaggaWagga  Location_Watsonia  Location_Williamtown  \\\n6049                    0                  0                     0   \n6050                    0                  0                     0   \n6052                    0                  0                     0   \n6053                    0                  0                     0   \n6054                    0                  0                     0   \n6055                    0                  0                     0   \n6056                    0                  0                     0   \n6057                    0                  0                     0   \n6058                    0                  0                     0   \n6059                    0                  0                     0   \n\n      Location_Woomera  \n6049                 0  \n6050                 0  \n6052                 0  \n6053                 0  \n6054                 0  \n6055                 0  \n6056                 0  \n6057                 0  \n6058                 0  \n6059                 0  \n\n[10 rows x 95 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MinTemp</th>\n      <th>MaxTemp</th>\n      <th>Rainfall</th>\n      <th>Evaporation</th>\n      <th>Sunshine</th>\n      <th>WindGustSpeed</th>\n      <th>WindSpeed9am</th>\n      <th>WindSpeed3pm</th>\n      <th>Humidity9am</th>\n      <th>Humidity3pm</th>\n      <th>...</th>\n      <th>Location_PerthAirport</th>\n      <th>Location_Portland</th>\n      <th>Location_Sale</th>\n      <th>Location_Sydney</th>\n      <th>Location_SydneyAirport</th>\n      <th>Location_Townsville</th>\n      <th>Location_WaggaWagga</th>\n      <th>Location_Watsonia</th>\n      <th>Location_Williamtown</th>\n      <th>Location_Woomera</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6049</th>\n      <td>17.9</td>\n      <td>35.2</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>12.3</td>\n      <td>48.0</td>\n      <td>6.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>13.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6050</th>\n      <td>18.4</td>\n      <td>28.9</td>\n      <td>0.0</td>\n      <td>14.8</td>\n      <td>13.0</td>\n      <td>37.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>30.0</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6052</th>\n      <td>19.4</td>\n      <td>37.6</td>\n      <td>0.0</td>\n      <td>10.8</td>\n      <td>10.6</td>\n      <td>46.0</td>\n      <td>30.0</td>\n      <td>15.0</td>\n      <td>42.0</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6053</th>\n      <td>21.9</td>\n      <td>38.4</td>\n      <td>0.0</td>\n      <td>11.4</td>\n      <td>12.2</td>\n      <td>31.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>37.0</td>\n      <td>22.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6054</th>\n      <td>24.2</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>11.2</td>\n      <td>8.4</td>\n      <td>35.0</td>\n      <td>17.0</td>\n      <td>13.0</td>\n      <td>19.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6055</th>\n      <td>27.1</td>\n      <td>36.1</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>43.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>26.0</td>\n      <td>19.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6056</th>\n      <td>23.3</td>\n      <td>34.0</td>\n      <td>0.0</td>\n      <td>9.8</td>\n      <td>12.6</td>\n      <td>41.0</td>\n      <td>17.0</td>\n      <td>19.0</td>\n      <td>33.0</td>\n      <td>15.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6057</th>\n      <td>16.1</td>\n      <td>34.2</td>\n      <td>0.0</td>\n      <td>14.6</td>\n      <td>13.2</td>\n      <td>37.0</td>\n      <td>15.0</td>\n      <td>6.0</td>\n      <td>25.0</td>\n      <td>9.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6058</th>\n      <td>19.0</td>\n      <td>35.5</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>12.3</td>\n      <td>48.0</td>\n      <td>30.0</td>\n      <td>9.0</td>\n      <td>46.0</td>\n      <td>28.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6059</th>\n      <td>19.7</td>\n      <td>35.5</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>12.7</td>\n      <td>41.0</td>\n      <td>15.0</td>\n      <td>17.0</td>\n      <td>61.0</td>\n      <td>14.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 95 columns</p>\n</div>"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"len(df_onehot_fulldrop) # 56420 / 145460: only 38.78% of the initial data survived to the end","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T01:32:31.768648Z","iopub.execute_input":"2025-04-29T01:32:31.768959Z","iopub.status.idle":"2025-04-29T01:32:31.774729Z","shell.execute_reply.started":"2025-04-29T01:32:31.768937Z","shell.execute_reply":"2025-04-29T01:32:31.773861Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"56420"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"Notice that we drop from around 140,000 rows to 56420 rows, discarding more than half of all data points.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\nfrom sklearn.model_selection import train_test_split\n\nscaler = StandardScaler()\n\nX = df_onehot_fulldrop.drop(columns=[\"RainToday\", \"RainTomorrow\", \"Rainfall\"])\ny = df_onehot_fulldrop[\"RainToday\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:14:35.764676Z","iopub.execute_input":"2025-04-28T17:14:35.765049Z","iopub.status.idle":"2025-04-28T17:14:35.953936Z","shell.execute_reply.started":"2025-04-28T17:14:35.765023Z","shell.execute_reply":"2025-04-28T17:14:35.953028Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# logreg with built-in 5-fold cross validation. Default penalty is L2.\n# Increased max_iter because the default of 100 wasn't enough to converge.\nlogregcv = LogisticRegressionCV(max_iter=256, cv=5, random_state=42)\nlogregcv.fit(X_train, y_train)\n\ny_pred_test = logregcv.predict(X_test)\ny_pred_train = logregcv.predict(X_train)\n\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:14:39.636325Z","iopub.execute_input":"2025-04-28T17:14:39.636830Z","iopub.status.idle":"2025-04-28T17:14:54.456535Z","shell.execute_reply.started":"2025-04-28T17:14:39.636807Z","shell.execute_reply":"2025-04-28T17:14:54.455827Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8423\nModel accuracy score (against training set): 0.8484\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"logreg = LogisticRegression(random_state=42)\nlogreg.fit(X_train, y_train)\n\ny_pred_test = logreg.predict(X_test)\ny_pred_train = logreg.predict(X_train)\n\nfrom sklearn.metrics import accuracy_score\n\n# Check accuracy against both train and test, see if there is a major difference\nprint('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\nprint('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:17:23.825738Z","iopub.execute_input":"2025-04-28T17:17:23.826124Z","iopub.status.idle":"2025-04-28T17:17:24.729416Z","shell.execute_reply.started":"2025-04-28T17:17:23.826088Z","shell.execute_reply":"2025-04-28T17:17:24.726322Z"}},"outputs":[{"name":"stdout","text":"Model accuracy score (against testing set): 0.8427\nModel accuracy score (against training set): 0.8479\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"# visually confirming that the predictions and y_test do add up\n# This is for the base LogReg, not LogRegCV.\nsum(abs(y_pred_test - y_test)), len(y_test)\n# similar performances.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T17:17:34.429032Z","iopub.execute_input":"2025-04-28T17:17:34.429316Z","iopub.status.idle":"2025-04-28T17:17:34.437705Z","shell.execute_reply.started":"2025-04-28T17:17:34.429297Z","shell.execute_reply":"2025-04-28T17:17:34.436880Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"(1775, 11284)"},"metadata":{}}],"execution_count":53},{"cell_type":"markdown","source":"Despite a significant cut to the number of rows for train/test purposes, the logreg models still performed about the same as previously.\n\n## Tests: dropping outliers\n\nThis is a hunch Jason developed after some work on the linear regression section. Below is a quick review of the statistic distribution of the Rainfall feature.","metadata":{}},{"cell_type":"code","source":"df_r = df[\"Rainfall\"]\ndf_r.describe(), df_r[df_r<20].describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:07:32.914669Z","iopub.execute_input":"2025-04-29T02:07:32.915637Z","iopub.status.idle":"2025-04-29T02:07:32.940821Z","shell.execute_reply.started":"2025-04-29T02:07:32.915608Z","shell.execute_reply":"2025-04-29T02:07:32.939943Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"(count    142199.000000\n mean          2.360918\n std           8.478060\n min           0.000000\n 25%           0.000000\n 50%           0.000000\n 75%           0.800000\n max         371.000000\n Name: Rainfall, dtype: float64,\n count    138116.000000\n mean          1.254910\n std           3.150981\n min           0.000000\n 25%           0.000000\n 50%           0.000000\n 75%           0.400000\n max          19.800000\n Name: Rainfall, dtype: float64)"},"metadata":{}}],"execution_count":76},{"cell_type":"markdown","source":"As seen above, there are 142199 valid entries in the Rainfall column (there's a few thousand missing values). The vast majority of them have rainfall levels of less than 20 centimeters (138116 of them). Of the remainder, their values go as high as 371 centimeters. Let's take a look at what these outliers look like.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(df_r[df_r>=20], bins=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:07:35.604480Z","iopub.execute_input":"2025-04-29T02:07:35.604825Z","iopub.status.idle":"2025-04-29T02:07:35.864433Z","shell.execute_reply.started":"2025-04-29T02:07:35.604801Z","shell.execute_reply":"2025-04-29T02:07:35.863536Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n","output_type":"stream"},{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"(array([915., 605., 469., 378., 298., 248., 159., 134., 125., 104.,  83.,\n         63.,  59.,  42.,  44.,  36.,  41.,  31.,  29.,  25.,  20.,  18.,\n         10.,  12.,  17.,  13.,  11.,  10.,   7.,   3.,   6.,   3.,   3.,\n          3.,   6.,   5.,   3.,   2.,   4.,   4.,   2.,   5.,   2.,   1.,\n          3.,   1.,   5.,   0.,   1.,   1.,   0.,   0.,   0.,   3.,   1.,\n          1.,   1.,   0.,   1.,   0.,   0.,   1.,   1.,   0.,   1.,   0.,\n          0.,   0.,   0.,   0.,   1.,   0.,   0.,   1.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          2.]),\n array([ 20.  ,  23.51,  27.02,  30.53,  34.04,  37.55,  41.06,  44.57,\n         48.08,  51.59,  55.1 ,  58.61,  62.12,  65.63,  69.14,  72.65,\n         76.16,  79.67,  83.18,  86.69,  90.2 ,  93.71,  97.22, 100.73,\n        104.24, 107.75, 111.26, 114.77, 118.28, 121.79, 125.3 , 128.81,\n        132.32, 135.83, 139.34, 142.85, 146.36, 149.87, 153.38, 156.89,\n        160.4 , 163.91, 167.42, 170.93, 174.44, 177.95, 181.46, 184.97,\n        188.48, 191.99, 195.5 , 199.01, 202.52, 206.03, 209.54, 213.05,\n        216.56, 220.07, 223.58, 227.09, 230.6 , 234.11, 237.62, 241.13,\n        244.64, 248.15, 251.66, 255.17, 258.68, 262.19, 265.7 , 269.21,\n        272.72, 276.23, 279.74, 283.25, 286.76, 290.27, 293.78, 297.29,\n        300.8 , 304.31, 307.82, 311.33, 314.84, 318.35, 321.86, 325.37,\n        328.88, 332.39, 335.9 , 339.41, 342.92, 346.43, 349.94, 353.45,\n        356.96, 360.47, 363.98, 367.49, 371.  ]),\n <BarContainer object of 100 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":77},{"cell_type":"markdown","source":"The few thousand rows with Rainfall >= 20 demonstrates a strong skew to the right with a long tail of increasingly large outliers. It may be possible that these outliers are throwing off our models. Here we used scipy's z-score statistics function to eliminate all rows where the Rainfall value is more than 3 standard deviations away from the mean.","metadata":{}},{"cell_type":"code","source":"df_nooutliers = df_onehot[np.abs(stats.zscore(df_onehot[\"Rainfall\"])) < 3] # Based on the original preparation\ndf_nooutliers2 = df_onehot_fulldrop[np.abs(stats.zscore(df_onehot_fulldrop[\"Rainfall\"])) < 3] # with dropping all rows w/ missing values\\\ndf_nooutliers3 = df_onehot_full[np.abs(stats.zscore(df_onehot_full[\"Rainfall\"])) < 3] # With keeping everything beforehand","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:26:06.738015Z","iopub.execute_input":"2025-04-29T02:26:06.738366Z","iopub.status.idle":"2025-04-29T02:26:06.886810Z","shell.execute_reply.started":"2025-04-29T02:26:06.738343Z","shell.execute_reply":"2025-04-29T02:26:06.885996Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# df_nooutliers = df_onehot[df_onehot[\"Rainfall\"] <= 20] # Based on the original preparation\n# df_nooutliers2 = df_onehot_fulldrop[df_onehot_fulldrop[\"Rainfall\"] <= 20] # with dropping all rows w/ missing values\n#from sklearn.metrics import accuracy_score\nprint('See the for loop definition to know which data set is being used.')\nfor df in [df_nooutliers, df_nooutliers2, df_nooutliers3]:\n    X = df.drop(columns=[\"RainTomorrow\", \"RainToday\", \"Rainfall\"])\n    y = df[\"RainToday\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    \n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n\n    # logreg with built-in 5-fold cross validation. Default penalty is L2.\n    # Increased max_iter because the default of 100 wasn't enough to converge.\n    logregcv = LogisticRegressionCV(max_iter=256, cv=5, random_state=42)\n    logregcv.fit(X_train, y_train)\n    \n    y_pred_test = logregcv.predict(X_test)\n    y_pred_train = logregcv.predict(X_train)\n    print('LogRegCV')\n    print('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n    print('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))\n\n    logreg = LogisticRegression(random_state=42)\n    logreg.fit(X_train, y_train)\n    \n    y_pred_test = logreg.predict(X_test)\n    y_pred_train = logreg.predict(X_train)\n    \n    # Check accuracy against both train and test, see if there is a major difference\n    print('LogReg')\n    print('Model accuracy score (against testing set): {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n    print('Model accuracy score (against training set): {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:26:54.653317Z","iopub.execute_input":"2025-04-29T02:26:54.653602Z","iopub.status.idle":"2025-04-29T02:27:54.207095Z","shell.execute_reply.started":"2025-04-29T02:26:54.653584Z","shell.execute_reply":"2025-04-29T02:27:54.206302Z"}},"outputs":[{"name":"stdout","text":"See the for loop definition to know which data set is being used.\nLogRegCV\nModel accuracy score (against testing set): 0.8411\nModel accuracy score (against training set): 0.8363\nLogReg\nModel accuracy score (against testing set): 0.8411\nModel accuracy score (against training set): 0.8363\nLogRegCV\nModel accuracy score (against testing set): 0.8461\nModel accuracy score (against training set): 0.8497\nLogReg\nModel accuracy score (against testing set): 0.8461\nModel accuracy score (against training set): 0.8496\nLogRegCV\nModel accuracy score (against testing set): 0.8439\nModel accuracy score (against training set): 0.8422\nLogReg\nModel accuracy score (against testing set): 0.8439\nModel accuracy score (against training set): 0.8422\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"len(df_nooutliers), len(df_nooutliers2), len(df_nooutliers3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:27:54.273374Z","iopub.execute_input":"2025-04-29T02:27:54.273707Z","iopub.status.idle":"2025-04-29T02:27:54.294524Z","shell.execute_reply.started":"2025-04-29T02:27:54.273682Z","shell.execute_reply":"2025-04-29T02:27:54.293682Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"(111761, 55258, 142978)"},"metadata":{}}],"execution_count":92},{"cell_type":"markdown","source":"The data set with a full drop of both outliers and all rows with missing values seem to lead to minor model performance improvements.","metadata":{}},{"cell_type":"markdown","source":"## Tests: Other classifier models\n\nThis section came about after Jason referenced the example project report the professor shared to determine what goes into making a high-quality report and noticed that whoever wrote that report also tested kNearestNeighbors and Random Forest models for regression and classification work.\n\nHere we will try to see if the aforementioned models might perform better than the Logistic Regression models we attempted earlier.\n\nFor reference, here are all of the data sets we prepared:\n\nname | description\n---- | ----\ndf_onehot | original preparation method (drop 6 columns, drop missing value rows)\ndf_onehot2 | partial filling of missing values (drop 6 columns, impute missing values)\ndf_onehot_full | keep everything (no dropping rows or columns, impute all missing values)\ndf_onehot_fulldrop | drop every row with missing values\ndf_nooutliers | df_onehot but with outliers removed\ndf_nooutliers2 | df_onehot_fulldrop with outliers removed\ndf_nooutliers3 | df_onehot_full with outliers removed","metadata":{}},{"cell_type":"code","source":"for df in [df_onehot, df_onehot2, df_onehot_full, df_onehot_fulldrop, df_nooutliers, df_nooutliers2, df_nooutliers3]:\n    X = df.drop(columns=[\"RainTomorrow\", \"RainToday\", \"Rainfall\"])\n    y = df[\"RainToday\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    forest = RandomForestClassifier()\n    forest.fit(X_train, y_train)\n    score = forest.score(X_test, y_test)\n    print(f\"Random forest score (see table for which dataset this is) is {score}\")\n    print(\"=\"*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:28:10.519780Z","iopub.execute_input":"2025-04-29T02:28:10.520571Z","iopub.status.idle":"2025-04-29T02:30:47.118725Z","shell.execute_reply.started":"2025-04-29T02:28:10.520539Z","shell.execute_reply":"2025-04-29T02:30:47.117826Z"}},"outputs":[{"name":"stdout","text":"Random forest score (see table for which dataset this is) is 0.849621745249824\n====================\nRandom forest score (see table for which dataset this is) is 0.8501054852320675\n====================\nRandom forest score (see table for which dataset this is) is 0.8543585865530042\n====================\nRandom forest score (see table for which dataset this is) is 0.8533321517192485\n====================\nRandom forest score (see table for which dataset this is) is 0.8546951192233705\n====================\nRandom forest score (see table for which dataset this is) is 0.8537821208830981\n====================\nRandom forest score (see table for which dataset this is) is 0.8562736046999581\n====================\n","output_type":"stream"}],"execution_count":93},{"cell_type":"code","source":"for df in [df_onehot, df_onehot2, df_onehot_full, df_onehot_fulldrop, df_nooutliers, df_nooutliers2]:\n    X = df.drop(columns=[\"RainTomorrow\", \"RainToday\", \"Rainfall\"])\n    y = df[\"RainToday\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    knn = KNeighborsClassifier(weights=\"distance\", p=2)\n    knn.fit(X_train, y_train)\n    score = knn.score(X_test, y_test)\n    print(f\"kNN score (see table for which dataset this is) is {score}\")\n    print(\"=\"*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:31:31.559495Z","iopub.execute_input":"2025-04-29T02:31:31.559821Z","iopub.status.idle":"2025-04-29T02:32:21.137963Z","shell.execute_reply.started":"2025-04-29T02:31:31.559797Z","shell.execute_reply":"2025-04-29T02:32:21.137230Z"}},"outputs":[{"name":"stdout","text":"kNN score (see table for which dataset this is) is 0.7916959887403238\n====================\nkNN score (see table for which dataset this is) is 0.7933544303797468\n====================\nkNN score (see table for which dataset this is) is 0.7966107520967963\n====================\nkNN score (see table for which dataset this is) is 0.7908543069833393\n====================\nkNN score (see table for which dataset this is) is 0.8036952534335436\n====================\nkNN score (see table for which dataset this is) is 0.7965979008324285\n====================\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"The Random Forest model displayed comparable performance compared to the LinReg model while the kNN model did a little bit worse.\n\nThis concludes our experiments on predicting the RainToday value.","metadata":{}},{"cell_type":"markdown","source":"## Training and Testing 2: LinReg model\n\nThe goal now is to predict the Rainfall value (a numerical feature) instead of RainToday. We will begin with a linear regression model snd run through the several data sets described above.","metadata":{}},{"cell_type":"code","source":"for df in [df_onehot, df_onehot2, df_onehot_full, df_onehot_fulldrop, df_nooutliers, df_nooutliers2, df_nooutliers3]:\n    scaler = StandardScaler()\n    \n    X = df.drop(columns=[\"RainTomorrow\", \"Rainfall\"])\n    y = df[\"Rainfall\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    \n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    linreg = LinearRegression()\n    linreg.fit(X_train, y_train)\n    score = linreg.score(X_test, y_test)\n    print(f\"LinReg score (see table for which dataset this is) is {score}\")\n    print(\"=\"*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:41:40.381760Z","iopub.execute_input":"2025-04-29T02:41:40.382092Z","iopub.status.idle":"2025-04-29T02:41:47.123909Z","shell.execute_reply.started":"2025-04-29T02:41:40.382069Z","shell.execute_reply":"2025-04-29T02:41:47.122581Z"}},"outputs":[{"name":"stdout","text":"LinReg score (see table for which dataset this is) is 0.2856444686219739\n====================\nLinReg score (see table for which dataset this is) is 0.29259209176370915\n====================\nLinReg score (see table for which dataset this is) is 0.2893275001577076\n====================\nLinReg score (see table for which dataset this is) is 0.32659483079488805\n====================\nLinReg score (see table for which dataset this is) is 0.5049104033385872\n====================\nLinReg score (see table for which dataset this is) is 0.535738490137553\n====================\nLinReg score (see table for which dataset this is) is 0.5192543435481108\n====================\n","output_type":"stream"}],"execution_count":98},{"cell_type":"markdown","source":"Here we see a much more noticeable effect on removing outliers: the LinReg model's accuracy went from around 0.3 +- 0.02 up to 0.52 += 0.02. This still isn't \"accurate enough for useful predictions\" territory, but it's significant improvement from before.","metadata":{}},{"cell_type":"markdown","source":"## Test: PCA\n\nOn a related tangent: Can we dimensionally reduce the data using PCA while still keeping roughly similar performances?","metadata":{}},{"cell_type":"code","source":"print(\"See the table for which dataset is being used.\")\nfor df in [df_onehot, df_onehot2, df_onehot_full, df_onehot_fulldrop, df_nooutliers, df_nooutliers2, df_nooutliers3]:\n    for compcount in [4, 8, 16, 32, 48, 55, 62]: # 62 is same as keeping all values\n        scaler = StandardScaler()\n        X = df.drop(columns=[\"RainTomorrow\", \"Rainfall\"])\n        y = df[\"Rainfall\"]\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n        \n        X_train = scaler.fit_transform(X_train)\n        \n        X_test = scaler.transform(X_test)\n        pca = PCA(n_components=compcount)\n        X_train_pca = pca.fit_transform(X_train)\n        X_test_pca = pca.transform(X_test)\n        #X_train_pca = scaler.fit_transform(X_train_pca)\n        #X_test_pca = scaler.transform(X_test_pca)\n        \n        linreg3 = LinearRegression()\n        linreg3.fit(X_train_pca, y_train)\n        \n        scores = cross_validate(linreg3, X_test_pca, y_test, cv=5,\n                                scoring=(\"r2\", \"neg_mean_squared_error\"),\n                                return_train_score=True)\n        scores\n        print(f\"LinReg training with PCA keeping {compcount} features: {linreg3.score(X_test_pca, y_test)}\")\n    print(\"=\"*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T02:46:28.352439Z","iopub.execute_input":"2025-04-29T02:46:28.353172Z","iopub.status.idle":"2025-04-29T02:47:52.662492Z","shell.execute_reply.started":"2025-04-29T02:46:28.353148Z","shell.execute_reply":"2025-04-29T02:47:52.659865Z"}},"outputs":[{"name":"stdout","text":"See the table for which dataset is being used.\nLinReg training with PCA keeping 4 features: 0.08903688708937885\nLinReg training with PCA keeping 8 features: 0.17982119217874182\nLinReg training with PCA keeping 16 features: 0.18615197556451724\nLinReg training with PCA keeping 32 features: 0.19191499293290026\nLinReg training with PCA keeping 48 features: 0.27873374052923894\nLinReg training with PCA keeping 55 features: 0.28170549450361215\nLinReg training with PCA keeping 62 features: 0.2856347385593341\n====================\nLinReg training with PCA keeping 4 features: 0.16905531726251644\nLinReg training with PCA keeping 8 features: 0.1749443542887602\nLinReg training with PCA keeping 16 features: 0.1844992785687004\nLinReg training with PCA keeping 32 features: 0.18849247586299334\nLinReg training with PCA keeping 48 features: 0.28487567768186717\nLinReg training with PCA keeping 55 features: 0.29029284744878614\nLinReg training with PCA keeping 62 features: 0.29260116581620854\n====================\nLinReg training with PCA keeping 4 features: 0.12181956478981615\nLinReg training with PCA keeping 8 features: 0.1333942006942559\nLinReg training with PCA keeping 16 features: 0.13984302728958498\nLinReg training with PCA keeping 32 features: 0.14869421012701334\nLinReg training with PCA keeping 48 features: 0.1560886128102439\nLinReg training with PCA keeping 55 features: 0.15978882599920197\nLinReg training with PCA keeping 62 features: 0.16553597136160614\n====================\nLinReg training with PCA keeping 4 features: 0.13449485022634833\nLinReg training with PCA keeping 8 features: 0.1501772374797874\nLinReg training with PCA keeping 16 features: 0.15181360344586214\nLinReg training with PCA keeping 32 features: 0.1560577801055849\nLinReg training with PCA keeping 48 features: 0.1698972796756727\nLinReg training with PCA keeping 55 features: 0.18181942633876258\nLinReg training with PCA keeping 62 features: 0.25927285006542256\n====================\nLinReg training with PCA keeping 4 features: 0.15060362314497322\nLinReg training with PCA keeping 8 features: 0.2748027149900203\nLinReg training with PCA keeping 16 features: 0.2850974366003114\nLinReg training with PCA keeping 32 features: 0.2920176996395778\nLinReg training with PCA keeping 48 features: 0.4960669336510267\nLinReg training with PCA keeping 55 features: 0.5030667689768449\nLinReg training with PCA keeping 62 features: 0.5049054448622372\n====================\nLinReg training with PCA keeping 4 features: 0.16525743953907002\nLinReg training with PCA keeping 8 features: 0.19417726884713626\nLinReg training with PCA keeping 16 features: 0.19665764207585923\nLinReg training with PCA keeping 32 features: 0.21161900543264212\nLinReg training with PCA keeping 48 features: 0.22935775898651656\nLinReg training with PCA keeping 55 features: 0.28952422492556584\nLinReg training with PCA keeping 62 features: 0.4227241205590292\n====================\nLinReg training with PCA keeping 4 features: 0.17075160615748064\nLinReg training with PCA keeping 8 features: 0.19716350995917142\nLinReg training with PCA keeping 16 features: 0.20778752975983628\nLinReg training with PCA keeping 32 features: 0.24333415455933938\nLinReg training with PCA keeping 48 features: 0.24246754190033215\nLinReg training with PCA keeping 55 features: 0.24759373250752637\nLinReg training with PCA keeping 62 features: 0.26447422030846235\n====================\n","output_type":"stream"}],"execution_count":100},{"cell_type":"markdown","source":"Using PCA to try to dimensionally reduce our data sets did not yield any noticeable results.","metadata":{}},{"cell_type":"markdown","source":"## Hunch: Manual Dimensional Reduction\n\nThis is a hunch that Jason had in the middle of building the notebook. What if we were to manually identify and select the top few features that are the most strongly correlated with Rainfall and try to train models on that? The goal here is to reduce training time (by reducing data required) without seriously hurting model performances.","metadata":{}},{"cell_type":"code","source":"non_numericals = [\"Date\", \"Location\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]\ndf_corr = df\nfor categorical in non_numericals:\n    #df_corr = pd.concat([df_onehot, pd.get_dummies(df_onehot[categorical], prefix=categorical)], axis=1)\n    if categorical in df_corr.columns:\n        df_corr = pd.concat([df_corr, pd.get_dummies(df_corr[categorical], prefix=categorical)], axis=1)\n        df_corr.drop(columns=categorical, inplace=True)\n        #df_corr.drop(columns=categorical, inplace=True)\n#df_onehot.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T03:14:52.765646Z","iopub.execute_input":"2025-04-29T03:14:52.765968Z","iopub.status.idle":"2025-04-29T03:14:53.078290Z","shell.execute_reply.started":"2025-04-29T03:14:52.765948Z","shell.execute_reply":"2025-04-29T03:14:53.077358Z"}},"outputs":[],"execution_count":165},{"cell_type":"code","source":"corr = df_corr.corr()[\"Rainfall\"]\npd.set_option('display.max_rows', 120) # so that everything prints without ... in the middle\nprint(corr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T03:14:54.417567Z","iopub.execute_input":"2025-04-29T03:14:54.418183Z","iopub.status.idle":"2025-04-29T03:14:59.911433Z","shell.execute_reply.started":"2025-04-29T03:14:54.418160Z","shell.execute_reply":"2025-04-29T03:14:59.910512Z"}},"outputs":[{"name":"stdout","text":"MinTemp                      0.103938\nMaxTemp                     -0.074992\nRainfall                     1.000000\nEvaporation                 -0.064351\nSunshine                    -0.227549\nWindGustSpeed                0.133659\nWindSpeed9am                 0.087338\nWindSpeed3pm                 0.057887\nHumidity9am                  0.224405\nHumidity3pm                  0.255755\nPressure9am                 -0.168154\nPressure3pm                 -0.126534\nCloud9am                     0.198528\nCloud3pm                     0.172403\nTemp9am                      0.011192\nTemp3pm                     -0.079657\nRainToday                         NaN\nRainTomorrow                -0.012890\nYear                        -0.008956\nMonth                       -0.031371\nDay                          0.001712\nLocation_Adelaide           -0.013970\nLocation_Albany             -0.001685\nLocation_Albury             -0.007751\nLocation_AliceSprings       -0.025733\nLocation_BadgerysCreek      -0.002870\nLocation_Ballarat           -0.010803\nLocation_Bendigo            -0.012915\nLocation_Brisbane            0.013943\nLocation_Cairns              0.058428\nLocation_Canberra           -0.011462\nLocation_Cobar              -0.021317\nLocation_CoffsHarbour        0.046388\nLocation_Dartmoor           -0.003675\nLocation_Darwin              0.048831\nLocation_GoldCoast           0.024306\nLocation_Hobart             -0.013559\nLocation_Katherine           0.010437\nLocation_Launceston         -0.006071\nLocation_Melbourne          -0.007642\nLocation_MelbourneAirport   -0.015763\nLocation_Mildura            -0.024546\nLocation_Moree              -0.012335\nLocation_MountGambier       -0.004758\nLocation_MountGinini         0.015870\nLocation_Newcastle           0.014141\nLocation_Nhil               -0.017767\nLocation_NorahHead           0.017557\nLocation_NorfolkIsland       0.013195\nLocation_Nuriootpa          -0.016815\nLocation_PearceRAAF         -0.011485\nLocation_Penrith            -0.003194\nLocation_Perth              -0.008127\nLocation_PerthAirport       -0.010393\nLocation_Portland            0.002932\nLocation_Richmond           -0.003820\nLocation_Sale               -0.014732\nLocation_SalmonGums         -0.022794\nLocation_Sydney              0.017620\nLocation_SydneyAirport       0.011248\nLocation_Townsville          0.019584\nLocation_Tuggeranong        -0.003408\nLocation_Uluru              -0.019342\nLocation_WaggaWagga         -0.011226\nLocation_Walpole             0.009158\nLocation_Watsonia           -0.008658\nLocation_Williamtown         0.019620\nLocation_Witchcliffe         0.009184\nLocation_Wollongong          0.021302\nLocation_Woomera            -0.032340\nWindGustDir_E               -0.014469\nWindGustDir_ENE             -0.013738\nWindGustDir_ESE             -0.002207\nWindGustDir_N               -0.027951\nWindGustDir_NE              -0.018942\nWindGustDir_NNE             -0.023723\nWindGustDir_NNW             -0.014760\nWindGustDir_NW              -0.003233\nWindGustDir_S                0.025812\nWindGustDir_SE               0.006942\nWindGustDir_SSE              0.008802\nWindGustDir_SSW              0.017379\nWindGustDir_SW               0.009136\nWindGustDir_W                0.011196\nWindGustDir_WNW              0.004891\nWindGustDir_WSW              0.012231\nWindDir9am_E                -0.028766\nWindDir9am_ENE              -0.025972\nWindDir9am_ESE              -0.015295\nWindDir9am_N                -0.030336\nWindDir9am_NE               -0.021940\nWindDir9am_NNE              -0.031015\nWindDir9am_NNW              -0.003145\nWindDir9am_NW                0.002954\nWindDir9am_S                 0.029157\nWindDir9am_SE               -0.000358\nWindDir9am_SSE               0.007511\nWindDir9am_SSW               0.031640\nWindDir9am_SW                0.042851\nWindDir9am_W                 0.025008\nWindDir9am_WNW               0.016300\nWindDir9am_WSW               0.030265\nWindDir3pm_E                -0.011933\nWindDir3pm_ENE              -0.011177\nWindDir3pm_ESE              -0.007743\nWindDir3pm_N                -0.026750\nWindDir3pm_NE               -0.023906\nWindDir3pm_NNE              -0.020995\nWindDir3pm_NNW              -0.018355\nWindDir3pm_NW               -0.005699\nWindDir3pm_S                 0.019491\nWindDir3pm_SE                0.005231\nWindDir3pm_SSE               0.012836\nWindDir3pm_SSW               0.027034\nWindDir3pm_SW                0.008748\nWindDir3pm_W                 0.015524\nWindDir3pm_WNW               0.008857\nWindDir3pm_WSW               0.013782\nName: Rainfall, dtype: float64\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":166},{"cell_type":"markdown","source":"There's a lot of features here, including the one-hot encoded ones. We arbitrarily chose to select features with an absolute correlation of more than 0.06.","metadata":{}},{"cell_type":"code","source":"for mydf in [df_onehot, df_onehot2, df_onehot_full, df_onehot_fulldrop, df_nooutliers, df_nooutliers2, df_nooutliers3]:\n    cols_list = corr[(corr>0.06) | (corr<-0.06)].index.to_list() + [\"RainToday\", \"RainTomorrow\", \"Rainfall\"]\n    common_cols = list(set(cols_list).intersection(set(mydf.columns))) # to prevent trying to select columns that some datsets don't have\n    df_snip = mydf[common_cols]\n    scaler = StandardScaler()\n    X = df_snip.drop(columns=[\"RainTomorrow\", \"Rainfall\"])\n    y = df_snip[\"Rainfall\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    \n    X_train = scaler.fit_transform(X_train)\n    \n    X_test = scaler.transform(X_test)\n    linreg = LinearRegression()\n    linreg.fit(X_train, y_train)\n    scores = cross_validate(linreg, X_test, y_test, cv=5,\n                        scoring=(\"r2\", \"neg_mean_squared_error\"),\n                        return_train_score=True)\n    #print(scores)\n    print(linreg.score(X_test, y_test))\n    #print(\"=\"*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T03:49:36.298272Z","iopub.execute_input":"2025-04-29T03:49:36.298883Z","iopub.status.idle":"2025-04-29T03:49:37.700416Z","shell.execute_reply.started":"2025-04-29T03:49:36.298847Z","shell.execute_reply":"2025-04-29T03:49:37.699631Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"0.2824199796598308\n0.2898019647427664\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"0.27900563175255744\n0.31663071546997246\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"0.5023896108638478\n0.5308627110254163\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"0.5136217687406022\n","output_type":"stream"}],"execution_count":193},{"cell_type":"markdown","source":"The warnings are a result of a small mix-up near the beginning of this notebook, as a result of the way the pandas replace() function handles column datatypes. They do not affect model performance but should be kept in mind.\n\nBy manually selecting 17 out of 120 columns (after using one-hot encoding to turn categoricals into numericals) based on correlation with RainToday, we achieved results almost as good as those on the full data set while keeping only 16 features in X.","metadata":{}},{"cell_type":"markdown","source":"## Test: Random Forest and kNN\n\nAs with the classification work, here we will see if Random Forest and kNN models can outdo Linear Regression.","metadata":{}},{"cell_type":"code","source":"for df in [df_onehot, df_onehot2, df_onehot_full, df_onehot_fulldrop, df_nooutliers, df_nooutliers2, df_nooutliers3]:\n    scaler = StandardScaler()\n    \n    X = df.drop(columns=[\"RainTomorrow\", \"Rainfall\"])\n    y = df[\"Rainfall\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    \n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    knn = KNeighborsRegressor(weights=\"distance\", p=2)\n    knn.fit(X_train, y_train)\n    score = knn.score(X_test, y_test)\n    print(f\"KNN score (see table for which dataset this is) is {score}\")\n    print(\"=\"*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T03:26:53.848848Z","iopub.execute_input":"2025-04-29T03:26:53.849175Z","iopub.status.idle":"2025-04-29T03:28:00.477964Z","shell.execute_reply.started":"2025-04-29T03:26:53.849152Z","shell.execute_reply":"2025-04-29T03:28:00.476569Z"}},"outputs":[{"name":"stdout","text":"KNN score (see table for which dataset this is) is 0.1818218031048897\n====================\nKNN score (see table for which dataset this is) is 0.17930828479483263\n====================\nKNN score (see table for which dataset this is) is 0.13096004712313813\n====================\nKNN score (see table for which dataset this is) is 0.12759317780394475\n====================\nKNN score (see table for which dataset this is) is 0.3513722156287866\n====================\nKNN score (see table for which dataset this is) is 0.224903412207902\n====================\nKNN score (see table for which dataset this is) is 0.25015523499991177\n====================\n","output_type":"stream"}],"execution_count":187},{"cell_type":"code","source":"for df in [df_onehot, df_onehot2, df_onehot_full, df_onehot_fulldrop, df_nooutliers, df_nooutliers2, df_nooutliers3]:\n    scaler = StandardScaler()\n    \n    X = df.drop(columns=[\"RainTomorrow\", \"Rainfall\"])\n    y = df[\"Rainfall\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n    \n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    forest = RandomForestRegressor(n_estimators=25) # using the default 100 trees is way too slow\n    forest.fit(X_train, y_train)\n    score = forest.score(X_test, y_test)\n    print(f\"Random Forest score (see table for which dataset this is) is {score}\")\n    print(\"=\"*20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T03:43:26.467239Z","iopub.execute_input":"2025-04-29T03:43:26.467555Z","iopub.status.idle":"2025-04-29T03:48:27.430464Z","shell.execute_reply.started":"2025-04-29T03:43:26.467533Z","shell.execute_reply":"2025-04-29T03:48:27.429610Z"}},"outputs":[{"name":"stdout","text":"Random Forest score (see table for which dataset this is) is 0.42025335093842\n====================\nRandom Forest score (see table for which dataset this is) is 0.3515581805466411\n====================\nRandom Forest score (see table for which dataset this is) is 0.3890904535357744\n====================\nRandom Forest score (see table for which dataset this is) is 0.4401590045415795\n====================\nRandom Forest score (see table for which dataset this is) is 0.5363037762103404\n====================\nRandom Forest score (see table for which dataset this is) is 0.575881130917028\n====================\nRandom Forest score (see table for which dataset this is) is 0.5550136024766908\n====================\n","output_type":"stream"}],"execution_count":192},{"cell_type":"markdown","source":"The random forests took longer than expected to train (around 2-3 minutes to train one forest). Even if it performed better, users should be wary of training times.\n\nThe kNN model did worse, as expected, while the Random Forest model seems to be slightly better than the Linear Regression model. However, the improvements are not significant and might not warrant the extra training time.","metadata":{}},{"cell_type":"markdown","source":"## Test: Escalate to ANN\n\nIt is possible that the LinearRegression model is not powerful enough to learn the mapping between X and y. We will now escalate to a fully-connected artificial neural network to try and predict Rainfall levels or RainToday values.","metadata":{}},{"cell_type":"code","source":"#from sklearn.neural_network import MLPRegressor\n\nscaler = StandardScaler()\n# Arbitrarily decided to use df_nooutliers2.\nX = df_nooutliers2.drop(columns=[\"RainTomorrow\", \"Rainfall\"])\ny = df_nooutliers2[\"Rainfall\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)\n\nmlp = MLPRegressor(hidden_layer_sizes = [64,32,16,8],\n                   activation=\"relu\", solver=\"adam\",\n                   verbose=True, learning_rate=\"adaptive\",\n                   learning_rate_init = 0.002, random_state=2501,\n                   batch_size=160, max_iter=512, early_stopping=True) # arbitrarily chosen hyperparams\n\nmlp.fit(X_train,y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:33:58.628110Z","iopub.execute_input":"2025-04-24T02:33:58.628388Z","iopub.status.idle":"2025-04-24T02:34:04.801044Z","shell.execute_reply.started":"2025-04-24T02:33:58.628371Z","shell.execute_reply":"2025-04-24T02:34:04.800443Z"}},"outputs":[{"name":"stdout","text":"Iteration 1, loss = 2.45617479\nValidation score: 0.593106\nIteration 2, loss = 2.01005582\nValidation score: 0.604379\nIteration 3, loss = 1.92232649\nValidation score: 0.595057\nIteration 4, loss = 1.86441848\nValidation score: 0.589246\nIteration 5, loss = 1.78263019\nValidation score: 0.578090\nIteration 6, loss = 1.71711793\nValidation score: 0.572280\nIteration 7, loss = 1.63281835\nValidation score: 0.549096\nIteration 8, loss = 1.54913821\nValidation score: 0.548659\nIteration 9, loss = 1.48230787\nValidation score: 0.515908\nIteration 10, loss = 1.37613104\nValidation score: 0.541589\nIteration 11, loss = 1.29136790\nValidation score: 0.506019\nIteration 12, loss = 1.20159057\nValidation score: 0.466115\nIteration 13, loss = 1.11485236\nValidation score: 0.489479\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","output_type":"stream"},{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"MLPRegressor(batch_size=160, early_stopping=True,\n             hidden_layer_sizes=[64, 128, 64], learning_rate='adaptive',\n             learning_rate_init=0.002, max_iter=512, random_state=2501,\n             verbose=True)","text/html":"<style>#sk-container-id-46 {color: black;background-color: white;}#sk-container-id-46 pre{padding: 0;}#sk-container-id-46 div.sk-toggleable {background-color: white;}#sk-container-id-46 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-46 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-46 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-46 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-46 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-46 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-46 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-46 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-46 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-46 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-46 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-46 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-46 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-46 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-46 div.sk-item {position: relative;z-index: 1;}#sk-container-id-46 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-46 div.sk-item::before, #sk-container-id-46 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-46 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-46 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-46 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-46 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-46 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-46 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-46 div.sk-label-container {text-align: center;}#sk-container-id-46 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-46 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-46\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(batch_size=160, early_stopping=True,\n             hidden_layer_sizes=[64, 128, 64], learning_rate=&#x27;adaptive&#x27;,\n             learning_rate_init=0.002, max_iter=512, random_state=2501,\n             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" checked><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(batch_size=160, early_stopping=True,\n             hidden_layer_sizes=[64, 128, 64], learning_rate=&#x27;adaptive&#x27;,\n             learning_rate_init=0.002, max_iter=512, random_state=2501,\n             verbose=True)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":150},{"cell_type":"markdown","source":"Admittedly we should have done this part using a GridSearchCV. However, this realization came after this chart was already assembled.\n\nChangelog of various model hyperparameters attempted and model performance:    \nweights | loss/valid scores | epochs | changes\n--- | --- | --- | ---\n[32, 64, 32] | 2.55 | n/a | did not record iteration count    \n[64, 64] | 1.795 | 512 | (reached limit, did not converge)    \n[64, 128, 64]| 1.676 | 512 | (reached limit, did not converge)    \n[64, 128, 64]| 1.676 | 512 | (switched learning rate from constant to adaptive; inverse scaling didn't get past 20 epochs)    \n[64, 128, 64]| 0.835 | 512 | (switched solver from SGD to Adam)    \n[64, 64] | 1.538 | 512 | (Adam, adaptive)    \n[64, 64] | 1.873 | 370 | (Adam, adaptive, changed activation to ReLU)    \n[64, 32, 16, 8] | 1.810 | 295 | (Adam, adaptive, ReLU)    \n[32, 32, 16, 8] | 2.386 | 314 | (placeholder \n[32, 32, 16, 8] | 2.06 | 69 | (default hyperparams, using df_snip to speed up training)    \n[32, 32, 16, 8] | 2.003/0.56 | 41 | (logistic -> ReLU, turned on early stopping)    \n[32, 32, 16, 8] | 1.927/0.584 | 85 | (ReLU, adaptive)    \n[32, 32, 16, 8] | 1.932/0.569 | 41 | (ReLU, Adam)     \n[64, 32, 16, 8] | 1.899/0.569 | 77 | (ReLU, adaptive)    \n[32, 32, 16, 8] | 1.826/0.559 | 28 | (using df_nooutliers2)    \n[32, 32, 16, 8] | 1.595/0.543 | 28 | (Adam, using df_nooutliers2)    \n[32, 32, 16, 8] | 1.460/0.526 | 16 | (ReLU, Adam, using df_nooutliers2)    \n[32, 32, 16, 8] | 1.217/0.468 | 16 | (ReLU, adaptive, using df_nooutliers2)    \n[64, 32, 16, 8] | 1.2749/0.519 | 77 | (ReLU, Adam, df_nooutliers2)    \n[64, 32, 16, 8] | 1.215/0.515 | 15 | (ReLU, Adam, df_nooutliers2, batch 128)    ","metadata":{}},{"cell_type":"code","source":"\"\"\"\nWe ran this cell repeatedly for different iterations of the multi-layer perceptron.\nPrevious runs are not reflected in the out section.\n\nScores against the testing sets (1.0 is best)\n[64, 128, 64], Adam + adaptive learning: -0.2779\n[64, 64], Adam + adaptive learning: -0.2354\n[64, 64], Adam + adaptive + ReLU: -0.0389\n[64, 32, 16, 8], Adam + adaptive + ReLU: -0.0400\n[32, 32, 16, 8], Adam + adaptive + ReLU: 0.0856\n[32, 32, 16, 8], default, using df_trim: 0.593\n[32, 32, 16, 8], ReLU + early stop: 0.595\n[32, 32, 16, 8], ReLU + early stop + adaptive: 0.598\n[32, 32, 16, 8], ReLU + early stop + Adam: 0.595\n[64, 32, 16, 8]: ReLU + early stop: 0.598\n[32, 32, 16, 8]: df_nooutliers2: 0.604\n[32, 32, 16, 8]: ReLU + Adam + df_nooutliers2: 0.596\n[32, 32, 16, 8]: ReLU + adaptive + df_nooutliers2: 0.600\n[64, 32, 16, 8]: ReLU + Adam + df_nooutliers2: 0.590\n[64, 32, 16, 8]: ReLU + Adam + df_nooutliers2 + batch 128: 0.597\n\"\"\"\n\nmlp.score(X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:34:09.517113Z","iopub.execute_input":"2025-04-24T02:34:09.517386Z","iopub.status.idle":"2025-04-24T02:34:09.558677Z","shell.execute_reply.started":"2025-04-24T02:34:09.517372Z","shell.execute_reply":"2025-04-24T02:34:09.557732Z"}},"outputs":[{"execution_count":151,"output_type":"execute_result","data":{"text/plain":"0.5952649510726109"},"metadata":{}}],"execution_count":151},{"cell_type":"markdown","source":"This is something we considered near the end of the development and reporting process: What results might we find from trying to apply GridSearchCV to find the best hyperparameters for a given X and y?\n\nThe printed text below the following cell was due to a stray MLPRegressor training line left during running. We have since then removed that line. Due to the extended time required to run the cell, we will not re-run the cell and instead leave the output as-is.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nscaler = StandardScaler()\n# Arbitrarily decided to use df_nooutliers2.\nX = df_nooutliers2.drop(columns=[\"RainTomorrow\", \"Rainfall\", \"RainToday\"])\ny = df_nooutliers2[\"RainToday\"]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\nX_train = scaler.fit_transform(X_train)\n\nX_test = scaler.transform(X_test)\n\n# Tests different hyperparameters for RandomForestRegressor to see which is best\nparam_grid = {\n    \"hidden_layer_sizes\" : [[64,32,16,8,1], [32,16,8,1]],\n    \"activation\" : [\"relu\", \"logistic\"],\n    \"solver\" : [\"adam\", \"sgd\"],\n    \"learning_rate_init\" : [0.001, 0.002],\n    \"random_state\" : [2501],\n    \"batch_size\": [16, 32, 64, 128, 160],\n    \"max_iter\": [512],\n    \"early_stopping\": [True],\n    \"learning_rate\": [\"adaptive\", \"constant\"]\n}\n\ngs = GridSearchCV(estimator=MLPRegressor(),\n              param_grid=param_grid,\n              scoring=\"r2\",\n              refit=True,\n              cv=5,\n              n_jobs=-1)\n\ngs.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T03:52:39.706113Z","iopub.execute_input":"2025-04-29T03:52:39.706434Z","iopub.status.idle":"2025-04-29T06:49:13.871181Z","shell.execute_reply.started":"2025-04-29T03:52:39.706411Z","shell.execute_reply":"2025-04-29T06:49:13.869912Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (512) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Iteration 1, loss = 0.32210559\nValidation score: -1.274508\nIteration 2, loss = 0.13413176\nValidation score: -0.213544\nIteration 3, loss = 0.08880816\nValidation score: -0.018840\nIteration 4, loss = 0.08178757\nValidation score: -0.000501\nIteration 5, loss = 0.08119332\nValidation score: -0.000004\nIteration 6, loss = 0.08116345\nValidation score: -0.000085\nIteration 7, loss = 0.08116211\nValidation score: -0.000137\nIteration 8, loss = 0.08116473\nValidation score: -0.000174\nIteration 9, loss = 0.08116204\nValidation score: -0.000408\nIteration 10, loss = 0.08116310\nValidation score: -0.000112\nIteration 11, loss = 0.08116384\nValidation score: -0.000171\nIteration 12, loss = 0.08116097\nValidation score: -0.000208\nIteration 13, loss = 0.08116151\nValidation score: -0.000092\nIteration 14, loss = 0.08116620\nValidation score: -0.000014\nIteration 15, loss = 0.08116370\nValidation score: -0.000418\nIteration 16, loss = 0.08116023\nValidation score: -0.000246\nValidation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n","output_type":"stream"},{"execution_count":196,"output_type":"execute_result","data":{"text/plain":"MLPRegressor(batch_size=160, early_stopping=True,\n             hidden_layer_sizes=[64, 32, 16, 8, 1], learning_rate='adaptive',\n             learning_rate_init=0.002, max_iter=512, random_state=2501,\n             verbose=True)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(batch_size=160, early_stopping=True,\n             hidden_layer_sizes=[64, 32, 16, 8, 1], learning_rate=&#x27;adaptive&#x27;,\n             learning_rate_init=0.002, max_iter=512, random_state=2501,\n             verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(batch_size=160, early_stopping=True,\n             hidden_layer_sizes=[64, 32, 16, 8, 1], learning_rate=&#x27;adaptive&#x27;,\n             learning_rate_init=0.002, max_iter=512, random_state=2501,\n             verbose=True)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":196},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nprint(\"Results for Grid Search w/ MLP:\")\npredictions = gs.predict(X_test)\nprint(f\"Best params found: {gs.best_params_}\")\nprint(f\"R-Squared: {gs.best_score_}, MSE: {mean_squared_error(y_test, predictions)}\")\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T07:01:00.915591Z","iopub.execute_input":"2025-04-29T07:01:00.915905Z","iopub.status.idle":"2025-04-29T07:01:00.951678Z","shell.execute_reply.started":"2025-04-29T07:01:00.915885Z","shell.execute_reply":"2025-04-29T07:01:00.950745Z"}},"outputs":[{"name":"stdout","text":"Results for Grid Search w/ MLP:\nBest params found: {'activation': 'relu', 'batch_size': 16, 'early_stopping': True, 'hidden_layer_sizes': [64, 32, 16, 8, 1], 'learning_rate': 'adaptive', 'learning_rate_init': 0.002, 'max_iter': 512, 'random_state': 2501, 'solver': 'adam'}\nR-Squared: 0.3663847235533797, MSE: 0.1022979589141665\n\n\n","output_type":"stream"}],"execution_count":200},{"cell_type":"markdown","source":"## Conclusions, findings\n\nAs a result of our work, we have arrived at a number of conclusions:\n\n#### Data Preprocessing\n- Even though data preprocessing and preparation wasn't a major part of the course curriculum, it still matters greatly for data science and machine learning work. After, garbage in, garbage out.\n- The models we tested - linear regression, kNN, random forest - were resistant to performance losses due to various approaches on dropping or imputing missing vaues. The different data sets made from each preparation method produced similar metrics.\n- The presence or absence of outliers (more specifically, in the Rainfall feature) did not greatly affect the classification models but did affect the regression models. This is mainly because the regression work was done against the Rainfall feature, where it had a great effect, while the classification work did not include that feature at all in X.\n\n#### Model prediction: RainToday\n- Our several tested models performed similarly to or worse than the model shown in the first Existing Work mentioned in our report. This occurred despite our various data preprocessing approaches and testings with a few different hyperparameter options. This may be the result of a natural level of noise in the data set, or of other variables not included in the data set contributing to whether it rained in a given place in Australia on a given day.\n- Test\n\n#### Model prediction: Rainfall\n- Our models did not perform particularly well when trying to regress for the Rainfall feature. The linear regression model performed better after being trained on a data set without outliers, but its metrics still did not reach satisfactory levels.\n- The Multi-Layer Perceptron model failed to surpass ","metadata":{}}]}